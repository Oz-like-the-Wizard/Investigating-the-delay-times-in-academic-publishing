{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 0: Reviewing Earlier Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As almost all the \"useful\" journals are identified for Q1 100K run, it is necessary to understand & review the Scimago datasets and the earlier functions. As it was seen in the previous steps, there are different versions (both online & offline), (two journals merged into one after a certain year) of some journals, it important to create a final eligible journals dataset to be merged with the date results. \n",
    "\n",
    "Another factor is that, during complete_one runs there are 30K+ articles that have completed the complete pipeline and ready to be examined. These articles are currenty stored in date_df & date_df_second_run datasets. These journals must be utilized for maximum efficiency and minimizing unnecessary time loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 32712: expected 20 fields, saw 21\\nSkipping line 32713: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 20760: expected 20 fields, saw 21\\nSkipping line 22914: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 19393: expected 20 fields, saw 21\\nSkipping line 19394: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 33757: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 19053: expected 20 fields, saw 21\\nSkipping line 20953: expected 20 fields, saw 21\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "from quartile import *\n",
    "\n",
    "\n",
    "#from scihub_upgraded import SciHub\n",
    "from crossref.restful import Works, Etiquette\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r retr_onetwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysis, it is seen that:\n",
    "\n",
    "* scimago.py -> is responsible for \"cat_sbj_dict\" that is used in quartile.py for \"Category\" to \"Subj. Area\" matching.\n",
    "\n",
    "* quartile.py -> is responsible for transforming Scimago excels into Q1-4 journal datasets. It also splits the journals based on their \"highest Q'd\" subj. areas, and splits their Total Docs. accordingly. As the remainder is distributed randomly, each run of this file generates slightly different doc. count for journals with \"multimode\"d subj areas. However, this should not effect the results greatly. The code also looks OK and efficient except for an .iterrows() loop, which can be improved but is ignored as it is not a huge performance or time issue.\n",
    "\n",
    "* As Unpy is removed from the overall pipeline, all Unpy related code is also shelved.\n",
    "\n",
    "* scimago_upgraded -> is responsible for the whole get_dates loop as the entire PDF & date extraction is now executed via SciHub.\n",
    "\n",
    "\n",
    "The biggest improvement area while we are waiting for Q1 useful journals to be completed are making sure that the final journal list is compatible with quartile.py flow.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 32712: expected 20 fields, saw 21\\nSkipping line 32713: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 20760: expected 20 fields, saw 21\\nSkipping line 22914: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 19393: expected 20 fields, saw 21\\nSkipping line 19394: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 33757: expected 20 fields, saw 21\\n'\n",
      "b'Skipping line 19053: expected 20 fields, saw 21\\nSkipping line 20953: expected 20 fields, saw 21\\n'\n"
     ]
    }
   ],
   "source": [
    "# Get q_df(s):\n",
    "q_df = quar_df_creator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create q_jrnl & q_pivor using q_df & article count target:\n",
    "\n",
    "q_jrnl, q_pivot = retr_ready(q_df,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ready = q_jrnl.groupby([q_jrnl[\"Issn\"].map(tuple),q_jrnl[\"Year\"]])[\"Total_Docs\"].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retr_onetwo.Total_Docs.equals(q_ready.Total_Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sbj_Area</th>\n",
       "      <th>Total_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Issn, Year, Sbj_Area, Total_Docs]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jrnl[q_jrnl.Issn.map(lambda x: any([iss.startswith(\" \") for iss in x]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERY IMPORTANT CODE BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13474065,  00214922, 2011)    2\n",
       "(13474065,  00214922, 2010)    2\n",
       "(00346861,  15390756, 2010)    1\n",
       "(15384721, 2017)               1\n",
       "(10902112,  10499644, 2017)    1\n",
       "                              ..\n",
       "(17453062,  17453054, 2013)    1\n",
       "(17543266,  17543274, 2013)    1\n",
       "(20728050,  02599422, 2013)    1\n",
       "(0046385X, 2013)               1\n",
       "(02572117, 2020)               1\n",
       "Length: 75528, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dftesto.apply(lambda x: x[\"Issn\"]+ (x[\"Year\"],), axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Total_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8586</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9262</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Issn  Total_Docs\n",
       "6712   (13474065,  00214922)           2\n",
       "6864   (13474065,  00214922)        1737\n",
       "6718   (13474065,  00214922)           2\n",
       "7018   (13474065,  00214922)        1758\n",
       "8219   (13474065,  00214922)        1741\n",
       "8586   (13474065,  00214922)        1496\n",
       "9327   (13474065,  00214922)        1451\n",
       "9262   (13474065,  00214922)        1174\n",
       "9998   (13474065,  00214922)        1418\n",
       "10566  (13474065,  00214922)        1275"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dftesto[q_df.Issn.map(lambda x: \"13474065\" in x)][[\"Issn\",\"Total_Docs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31196</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2010</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31197</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2011</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31198</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2012</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31199</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2013</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31200</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2016</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31201</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2017</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31202</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2018</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31203</th>\n",
       "      <td>(13474065,  00214922)</td>\n",
       "      <td>2019</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Issn  Year  Total_Docs\n",
       "31196  (13474065,  00214922)  2010        1739\n",
       "31197  (13474065,  00214922)  2011        1760\n",
       "31198  (13474065,  00214922)  2012        1741\n",
       "31199  (13474065,  00214922)  2013        1496\n",
       "31200  (13474065,  00214922)  2016        1451\n",
       "31201  (13474065,  00214922)  2017        1174\n",
       "31202  (13474065,  00214922)  2018        1418\n",
       "31203  (13474065,  00214922)  2019        1275"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ready[q_ready.Issn.map(lambda x:\"13474065\" in x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only USEFUL finding in this step is that, retr_complete_one has a slightly altered Issn column with fewer ISSN codes than a newly created version of it (q_ready).\n",
    "\n",
    "As a result, this column will be REPLACED once all the work in the previous nb is completed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Creating a COMPELETE (1st + 2nd run) date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r date_df\n",
    "%store -r second_run_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dois = set(date_df.index.tolist()).intersection(set(second_run_date_df.index.tolist()))\n",
    "date_df.drop(duplicate_dois, inplace=True)\n",
    "\n",
    "date_df_full = date_df.append(second_run_date_df,verify_integrity=True)\n",
    "date_df_full.drop(\"Year\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_df_full is created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'date_df_full' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store date_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"date_df_full\",\"wb\") as fp:\n",
    "    pickle.dump(date_df_full, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis below shows that, the missing (.) in the regex results in a 0.8% percent found date increase. This alone is not necessary for re-doing the entire dataset BUT:\n",
    "\n",
    "* we now have the direct URLs for the successful articles, which should quicken & simplify the process if we decide to re-run\n",
    "* KEYWORDS extraction might be necessary for future anaylsis, which would give us a second chance to loop through anyways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     990\n",
       "3       8\n",
       "21      1\n",
       "13      1\n",
       "Name: New_Results, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh = SciHub()\n",
    "new_date_regex_test = date_df_full[date_df_full.Results.map(len)==2].sample(1000)\n",
    "new_date_regex_test[\"New_Results\"] = new_date_regex_test.index.map(sh.get_dates)\n",
    "new_date_regex_test[\"New_Results\"].map(len).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1.A: date_df_full_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTD for date_df_full:\n",
    "\n",
    "* \"skipped\"  -> not filtered BUT in date_df_str_fail DONE(!)\n",
    "* \"published\" column function -> DONE!\n",
    "* \"Results\" column expand function -> DONE!\n",
    "* \"language\" analysis (can we extact the lang. from the title for non-en articles) -> can't extract dates if not in Eng. so will be DROPPED & DONE!\n",
    "* Check \"ISSN\" format \n",
    "* Simplify \"author\" column -> maybe create a author_df -> DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 128374 entries, 10.1002/aic.12400 to 10.1177/0096340214539115\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   reference-count         128374 non-null  int64 \n",
      " 1   publisher               128371 non-null  object\n",
      " 2   published-print         120056 non-null  object\n",
      " 3   is-referenced-by-count  128374 non-null  int64 \n",
      " 4   title                   128374 non-null  object\n",
      " 5   author                  120278 non-null  object\n",
      " 6   published-online        82614 non-null   object\n",
      " 7   reference               89462 non-null   object\n",
      " 8   container-title         128374 non-null  object\n",
      " 9   language                57136 non-null   object\n",
      " 10  issued                  128374 non-null  object\n",
      " 11  ISSN                    128374 non-null  object\n",
      " 12  subject                 128013 non-null  object\n",
      " 13  published               62215 non-null   object\n",
      " 14  Results                 128374 non-null  object\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 19.7+ MB\n"
     ]
    }
   ],
   "source": [
    "date_df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_not_in_Scihub    9485\n",
       "skipped                  3868\n",
       "cant_read_pdf             242\n",
       "direct_url_error           10\n",
       "pdf_bytes_error             7\n",
       "Name: Results, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1- \"not_in Scihub\" FIX (date_df_full):\n",
    "\n",
    "date_df_full.loc[date_df_full.Results.map(type)==str, \"Results\"] = date_df_full[date_df_full.Results.map(type)==str][\"Results\"].str.replace(\"article_not_in Scihub\",\"article_not_in_Scihub\")\n",
    "\n",
    "# STORED & DUMPED AFTER THIS\n",
    "\n",
    "date_df_full[date_df_full.Results.map(type)==str].Results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    78218\n",
       "3    36495\n",
       "Name: Results, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_full[date_df_full.Results.map(type)==list].Results.map(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- SPLITTING THE DATASETS (date_df_ok):\n",
    "\n",
    "date_df_str_fail = date_df_full[date_df_full.Results.map(type)==str].copy()\n",
    "\n",
    "date_df_ok = date_df_full[date_df_full.Results.map(type)==list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- \"RESULTS\" COLUMN ENGINEERING:\n",
    "def result_mapper(lst):\n",
    "    if len(lst) == 2:\n",
    "        return lst[0], np.nan, np.nan\n",
    "    elif len(lst) == 3:\n",
    "        return lst[0], lst[1], lst[2]\n",
    "\n",
    "date_df_ok[\"direct_url\"], date_df_ok[\"Rec_date\"], date_df_ok[\"Acc_date\"] = zip(*date_df_ok.Results.map(result_mapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'str'>    114759\n",
       "Name: direct_url, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_ok[\"direct_url\"].map(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'float'>       78245\n",
       "<class 'str'>         34050\n",
       "<class 'NoneType'>     2464\n",
       "Name: Rec_date, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_ok[\"Rec_date\"].map(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'float'>       78245\n",
       "<class 'str'>         30891\n",
       "<class 'NoneType'>     5623\n",
       "Name: Acc_date, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_ok[\"Acc_date\"].map(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- \"PUBLISHED\" COLUMN ENGINEERING:\n",
    "\n",
    "date_df_ok.loc[(date_df_ok.published.isna()) & (date_df_ok[\"published-print\"].isna()) & (date_df_ok[\"published-online\"].notna()),\"published\"] = date_df_ok.loc[(date_df_ok.published.isna()) & (date_df_ok[\"published-print\"].isna()) & (date_df_ok[\"published-online\"].notna()),\"published-online\"]\n",
    "date_df_ok.loc[(date_df_ok.published.isna()) & (date_df_ok[\"published-print\"].notna()) & (date_df_ok[\"published-online\"].isna()),\"published\"] = date_df_ok.loc[(date_df_ok.published.isna()) & (date_df_ok[\"published-print\"].notna()) & (date_df_ok[\"published-online\"].isna()),\"published-print\"]\n",
    "\n",
    "def earlier_date_part(row):\n",
    "    pp_year = row[\"published-print\"][\"date-parts\"][0][0]\n",
    "    po_year = row[\"published-online\"][\"date-parts\"][0][0]\n",
    "       \n",
    "    if pp_year<po_year:\n",
    "        return row[\"published-print\"]\n",
    "    elif po_year<pp_year:\n",
    "        return row[\"published-online\"]\n",
    "    else:\n",
    "        try:\n",
    "            pp_month = row[\"published-print\"][\"date-parts\"][0][1]\n",
    "        except IndexError:\n",
    "            pp_month = 12\n",
    "        try:\n",
    "            po_month = row[\"published-online\"][\"date-parts\"][0][1]\n",
    "        except IndexError:\n",
    "            po_month = 12\n",
    "        if pp_month<po_month:\n",
    "            return row[\"published-print\"]\n",
    "        elif po_month<pp_month:\n",
    "            return row[\"published-online\"]\n",
    "        else:\n",
    "            return row[\"published-online\"]\n",
    "\n",
    "\n",
    "date_df_ok.loc[date_df_ok.published.isna(),\"published\"] = date_df_ok[date_df_ok.published.isna()].apply(earlier_date_part, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- \"REFERENCE\" & \"LANGUAGE\" COLUMN ANALYSIS:\n",
    "\n",
    "# It seems that both columns are not useful, and will be dropped. They can be retrieved from date_df_full in the future if necessary.\n",
    "\n",
    "date_df_ok.drop([\"reference\",\"language\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- \"AUTHOR\" COLUMN ANALYSIS:\n",
    "\n",
    "date_df_ok.loc[date_df_ok.author.notna(),\"first_author\"] = date_df_ok[date_df_ok.author.notna()].author.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'date_df_ok' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store date_df_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"date_df_ok\",\"wb\") as fp:\n",
    "    pickle.dump(date_df_ok, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1.B: retr_complete_one & second_run_df analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r retr_complete_one\n",
    "%store -r second_run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74421 entries, 0 to 74420\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Issn           74421 non-null  object\n",
      " 1   Year           74421 non-null  int32 \n",
      " 2   Total_Docs     74421 non-null  int64 \n",
      " 3   Sample_Count   74421 non-null  int64 \n",
      " 4   CrossRef_retr  74421 non-null  object\n",
      " 5   DOI            74421 non-null  object\n",
      " 6   Results        64119 non-null  object\n",
      "dtypes: int32(1), int64(2), object(4)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "retr_complete_one.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 dataframes to work on:\n",
    "\n",
    "* no need for DOI info in any of them\n",
    "* no need for \"Sample_Count\"\n",
    "\n",
    "1- second_run_df:\n",
    "* replace Second_CR_retr with CrossRef_retr\n",
    "* get True & False from \"2nd_Results\"\n",
    "\n",
    "2- retr_compete_one:\n",
    "* drop all included in other 2\n",
    "* get True & False from \"Results\" \n",
    "\n",
    "3- missing49:\n",
    "* loop through CR + SH get_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing49 = retr_complete_one[(retr_complete_one.CrossRef_retr == True) & (retr_complete_one.Results.map(type)==float)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- second_run_df:\n",
    "\n",
    "second_run_df[\"SH_Results\"] = second_run_df[\"2nd_Results\"].map(lambda x: True if len(x)>0 else False)\n",
    "second_run_df.drop([\"Sample_Count\",\"CrossRef_retr\",\"DOI\",\"Results\",\"2nd_Results\"], axis=1, inplace=True)\n",
    "second_run_df.rename(columns={\"Second_CR_retr\":\"CR_Results\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- retr_complete_one:\n",
    "retr_complete_one.drop(second_run_df.index.tolist(), inplace=True)\n",
    "retr_complete_one.drop(missing49.index.tolist(), inplace=True)\n",
    "retr_complete_one[\"SH_Results\"] = True\n",
    "retr_complete_one.drop([\"Sample_Count\",\"DOI\",\"Results\"], axis=1, inplace=True)\n",
    "retr_complete_one.rename(columns={\"CrossRef_retr\":\"CR_Results\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- missing49:\n",
    "missing49.drop([\"Sample_Count\",\"DOI\",\"Results\"], axis=1, inplace=True)\n",
    "missing49.rename(columns={\"CrossRef_retr\":\"CR_Results\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- missing49 cont.:\n",
    "\n",
    "from scihub_upgraded import SciHub\n",
    "from crossref.restful import Works, Etiquette\n",
    "\n",
    "my_etiquette = Etiquette('Analysing Publishing Delay in Academic Journals', 'v2.0', 'https://github.com/Spidey0023/THEsis-Codes', 'oguzkokes@gmail.com')\n",
    "ogi_works = Works(etiquette=my_etiquette)\n",
    "\n",
    "sh = SciHub()\n",
    "\n",
    "# The full loop code for missing49:\n",
    "\n",
    "issn_rry = missing49.Issn.values\n",
    "year_rry = missing49.Year.values\n",
    "\n",
    "#second_run_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "miss49_meta_list = []\n",
    "miss49_sh_date_dict = {}\n",
    "useful_cols = ['DOI', 'references-count', 'publisher', 'published-print', 'is-referenced-by-count', 'title', 'author', 'published-online', 'reference', 'container-title', 'issued', 'ISSN', 'subject']\n",
    "\n",
    "for i in range(len(missing49)):\n",
    "    issn = issn_rry[i]\n",
    "    year = year_rry[i]\n",
    "    loop_meta = [w for w in ogi_works.filter(issn=issn, from_pub_date=year, until_pub_date=year, type=\"journal-article\").sample(1).select(useful_cols)] \n",
    "\n",
    "    if len(loop_meta) == 0:\n",
    "        missing49.loc[missing49.index[i],\"Second_CR_retr\"] = False\n",
    "    else:\n",
    "        missing49.loc[missing49.index[i],\"Second_CR_retr\"] = True\n",
    "        missing49.loc[missing49.index[i],\"DOI\"] = loop_meta[0][\"DOI\"]\n",
    "        miss49_sh_date_dict[loop_meta[0][\"DOI\"]] = sh.get_dates(loop_meta[0][\"DOI\"])\n",
    "\n",
    "    miss49_meta_list.extend(loop_meta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3- missing49 cont.:\n",
    "\n",
    "missing49[\"Results\"] = missing49.DOI.map(miss49_sh_date_dict)\n",
    "missing49[\"SH_Results\"] = missing49.Results.map(len) == 3\n",
    "missing49.drop([\"Second_CR_retr\",\"DOI\",\"Results\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all 3 journal related datasets: retr_onetwo\n",
    "\n",
    "retr_onetwo = pd.concat([second_run_df,retr_complete_one, missing49], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'retr_onetwo' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store retr_onetwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retr_onetwo\",\"wb\") as fp:\n",
    "    pickle.dump(retr_onetwo, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1.C: Add articles from missing49 to date_df_full & date_df_str_fail & date_df_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss49_df = pd.DataFrame(miss49_meta_list)\n",
    "miss49_df.set_index(\"DOI\",drop=True,inplace=True)\n",
    "miss49_df[\"Results\"] = miss49_df.index.map(miss49_sh_date_dict)\n",
    "miss49_df.rename(columns={\"references-count\":\"reference-count\"}, inplace=True)\n",
    "\n",
    "date_df_full = pd.concat([date_df_full,miss49_df],verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rather than looping again, date_df_ok & date_df_str_fail will be created again from date_df_full by going through the steps in the previous chapter. All datasets are SAVED & STORED again afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_df_ok\n",
    "\n",
    "retr_one_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: retr_onetwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working on date_df upgrades ona seperate nb, it would be time efficient to get any long runs on retr_onetwo out of the way. There are currently 2 improvement areas:\n",
    "\n",
    "1- replace retr_onetwo ISSN column with q_ready's ISSN column which has more ISSN numbers attached.\n",
    "\n",
    "2- to get CR_count fror journals, so that the Sample_count can be calculated accordingly. Because if a jrnl has less articles in CrossRef than Scimago Total Docs. it may cause issues during sampling. This will be done entirely with SumCetCet looping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "After some analysis regarding q_df, q_ready processes, it is seen that everything is in order & the number disperency is caused by duplicated journals as expected. The steps above can be executed. \n",
    "\n",
    "#### AS A BACKUP, retr_onetwo_oldissns will be pickled & dumped if any unforseen errors occur with the new ISSN column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_onetwo_oldissns = retr_onetwo.copy()\n",
    "\n",
    "with open(\"retr_onetwo_oldissns\",\"wb\") as fp:\n",
    "    pickle.dump(retr_onetwo_oldissns, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    52249\n",
       "1    21983\n",
       "3      189\n",
       "Name: Issn, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retr_onetwo.sort_index(inplace=True)\n",
    "\n",
    "retr_onetwo[\"Issn\"] = q_ready.Issn.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store retr_onetwo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retr_onetwo is now updated, STORED & DUMPED. We can create the SumCet loop for CR_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_Docs</th>\n",
       "      <th>CR_Results</th>\n",
       "      <th>SH_Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2010</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2011</td>\n",
       "      <td>315</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2012</td>\n",
       "      <td>347</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2013</td>\n",
       "      <td>422</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2014</td>\n",
       "      <td>359</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74416</th>\n",
       "      <td>[8756758X, 14602695]</td>\n",
       "      <td>2017</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74417</th>\n",
       "      <td>[8756758X, 14602695]</td>\n",
       "      <td>2018</td>\n",
       "      <td>199</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74418</th>\n",
       "      <td>[8756758X, 14602695]</td>\n",
       "      <td>2019</td>\n",
       "      <td>210</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74419</th>\n",
       "      <td>[8756758X, 14602695]</td>\n",
       "      <td>2020</td>\n",
       "      <td>221</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74420</th>\n",
       "      <td>[8756971X, 19436270]</td>\n",
       "      <td>2010</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74421 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Issn  Year  Total_Docs CR_Results  SH_Results\n",
       "0      [00011541, 15475905]  2010         294       True        True\n",
       "1      [00011541, 15475905]  2011         315       True       False\n",
       "2      [00011541, 15475905]  2012         347       True       False\n",
       "3      [00011541, 15475905]  2013         422       True        True\n",
       "4      [00011541, 15475905]  2014         359       True        True\n",
       "...                     ...   ...         ...        ...         ...\n",
       "74416  [8756758X, 14602695]  2017         170       True        True\n",
       "74417  [8756758X, 14602695]  2018         199       True        True\n",
       "74418  [8756758X, 14602695]  2019         210       True        True\n",
       "74419  [8756758X, 14602695]  2020         221       True        True\n",
       "74420  [8756971X, 19436270]  2010          69       True       False\n",
       "\n",
       "[74421 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retr_onetwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Loop for CR_Count: - DID NOT RUN & NO OGI VERSION!\n",
    "\n",
    "my_etiquette = Etiquette('Analysing Publishing Delay in Academic Journals', 'v2.0', 'https://github.com/Spidey0023/THEsis-Codes', 'oguzkokes@gmail.com')\n",
    "ogi_works = Works(etiquette=my_etiquette)\n",
    "\n",
    "issn_rry = retr_onetwo.Issn.values\n",
    "year_rry = retr_onetwo.Year.values\n",
    "\n",
    "for i in range(len(retr_onetwo)):\n",
    "    issn = issn_rry[i]\n",
    "    year = year_rry[i]\n",
    "    jrnl_count = ogi_works.filter(issn=issn, from_pub_date=year, until_pub_date=year, type=\"journal-article\").count() \n",
    "\n",
    "    retr_onetwo.loc[retr_onetwo.index[i],\"CR_Count\"] = jrnl_count\n",
    "\n",
    "\n",
    "with open(\"retr_onetwo\",\"wb\") as fp:\n",
    "    pickle.dump(retr_onetwo, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SumCet Loop for CR_Count:\n",
    "\n",
    "cet_retr_onetwo_cr_count = retr_onetwo[:40000]\n",
    "sum_retr_onetwo_cr_count = retr_onetwo[40000:]\n",
    "\n",
    "issn_rry = cet_retr_onetwo_cr_count.Issn.values\n",
    "year_rry = cet_retr_onetwo_cr_count.Year.values\n",
    "\n",
    "for i in range(len(retr_onetwo)):\n",
    "    issn = issn_rry[i]\n",
    "    year = year_rry[i]\n",
    "    jrnl_count = ogi_works.filter(issn=issn, from_pub_date=year, until_pub_date=year, type=\"journal-article\").count() \n",
    "\n",
    "    cet_retr_onetwo_cr_count.loc[cet_retr_onetwo_cr_count.index[i],\"CR_Count\"] = jrnl_count\n",
    "\n",
    "\n",
    "with open(\"cet_retr_onetwo_cr_count\",\"wb\") as fp:\n",
    "    pickle.dump(cet_retr_onetwo_cr_count, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SumCet loop is completed! The results are analysed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sum_retr_onetwo_cr_count\", \"rb\") as fp:\n",
    "    retr_onetwo_sum = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cet_retr_onetwo_cr_count\", \"rb\") as fp:\n",
    "    retr_onetwo_cet = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jrnls with less than 50% artcls available on CrossRef (cet): 1273\n",
      "Number of jrnls with less than 50% artcls available on CrossRef (sum): 1305\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of jrnls with less than 50% artcls available on CrossRef (cet): {len(retr_onetwo_cet[(retr_onetwo_cet.CR_Count<retr_onetwo_cet.Total_Docs*.5) & (retr_onetwo_cet.CR_Results==True)])}\")\n",
    "\n",
    "print(f\"Number of jrnls with less than 50% artcls available on CrossRef (sum): {len(retr_onetwo_sum[(retr_onetwo_sum.CR_Count<retr_onetwo_sum.Total_Docs*.5) & (retr_onetwo_sum.CR_Results==True)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jrnls with CR_Results but CR_Counts == 0 (cet): 0\n",
      " Jrnls with CR_Results but CR_Counts == 0 (sum): 6\n"
     ]
    }
   ],
   "source": [
    "print(f\" Jrnls with CR_Results but CR_Counts == 0 (cet): {len(retr_onetwo_cet[(retr_onetwo_cet.CR_Results) & (retr_onetwo_cet.CR_Count == 0)])}\")\n",
    "\n",
    "print(f\" Jrnls with CR_Results but CR_Counts == 0 (sum): {len(retr_onetwo_sum[(retr_onetwo_sum.CR_Results) & (retr_onetwo_sum.CR_Count == 0)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_Docs</th>\n",
       "      <th>CR_Results</th>\n",
       "      <th>SH_Results</th>\n",
       "      <th>CR_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43578</th>\n",
       "      <td>[15251403, 10947159]</td>\n",
       "      <td>2015</td>\n",
       "      <td>275</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43579</th>\n",
       "      <td>[15251403, 10947159]</td>\n",
       "      <td>2016</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43580</th>\n",
       "      <td>[15251403, 10947159]</td>\n",
       "      <td>2017</td>\n",
       "      <td>111</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43581</th>\n",
       "      <td>[15251403, 10947159]</td>\n",
       "      <td>2018</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68297</th>\n",
       "      <td>[20458932, 20458940]</td>\n",
       "      <td>2014</td>\n",
       "      <td>77</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68298</th>\n",
       "      <td>[20458932, 20458940]</td>\n",
       "      <td>2015</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Issn  Year  Total_Docs CR_Results  SH_Results  CR_Count\n",
       "43578  [15251403, 10947159]  2015         275       True        True       0.0\n",
       "43579  [15251403, 10947159]  2016         170       True        True       0.0\n",
       "43580  [15251403, 10947159]  2017         111       True        True       0.0\n",
       "43581  [15251403, 10947159]  2018         115       True        True       0.0\n",
       "68297  [20458932, 20458940]  2014          77       True        True       0.0\n",
       "68298  [20458932, 20458940]  2015          80       True        True       0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The problematic jrnls from sum_run:\n",
    "retr_onetwo_sum[(retr_onetwo_sum.CR_Results) & (retr_onetwo_sum.CR_Count == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concating back to retr_one_two & STORING & DUMPing\n",
    "\n",
    "The old version is already backed-up as \"retr_onetwo_old_issns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_onetwo = pd.concat([retr_onetwo_cet,retr_onetwo_sum],verify_integrity=True)\n",
    "retr_onetwo[\"CR_Count\"] = retr_onetwo.CR_Count.map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_Docs</th>\n",
       "      <th>CR_Results</th>\n",
       "      <th>SH_Results</th>\n",
       "      <th>CR_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2010</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2011</td>\n",
       "      <td>315</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2012</td>\n",
       "      <td>347</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2013</td>\n",
       "      <td>422</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[00011541, 15475905]</td>\n",
       "      <td>2014</td>\n",
       "      <td>359</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Issn  Year  Total_Docs CR_Results  SH_Results  CR_Count\n",
       "0  [00011541, 15475905]  2010         294       True        True       351\n",
       "1  [00011541, 15475905]  2011         315       True       False       361\n",
       "2  [00011541, 15475905]  2012         347       True       False       259\n",
       "3  [00011541, 15475905]  2013         422       True        True       343\n",
       "4  [00011541, 15475905]  2014         359       True        True       376"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The final version of retr_onetwo:\n",
    "retr_onetwo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'retr_onetwo' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store retr_onetwo\n",
    "\n",
    "with open(\"retr_onetwo\",\"wb\") as fp:\n",
    "    pickle.dump(retr_onetwo, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retr_onetwo is now ready for 100K run. HOWEVER, before the 100K run, there are upgrades that needs to be completed on date_df_ok. These are:\n",
    "\n",
    "1- re-check DATE info with the new regex patterns\n",
    "\n",
    "2- create & get AFFILIATION info from PDFs\n",
    "* Get & score:\n",
    "    * E-mail\n",
    "    * Uni name\n",
    "    * Country name \n",
    "\n",
    "3- get ABSTRACT from articles or PDFs\n",
    "\n",
    "This notebook will be paused again, to work on the upgrades & will be continued once everything is ready for the \"final\" & third date_df run. Based on the new info, will create retr_three & date_df_three. \n",
    "\n",
    "retr_three will be used for completing 100K run & date_df_three will be concat'd with the new articles and the whole process will be completed, reaedy for analysis!!1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### WE ARE BACK!\n",
    "\n",
    "The upgrade tests are completed! The next steps for the project are as follows:\n",
    "\n",
    "1 - run sh-wartortle on date_df_ok \n",
    "\n",
    "    * re-check dates\n",
    "\n",
    "    * get affiliation\n",
    "\n",
    "    * get keywords\n",
    "\n",
    "2 - calculate sample_count for each jrnl in retr_onetwo using q_matrix & sbj_areas\n",
    "\n",
    "    * artciles in data_df_ok should be excluded\n",
    "\n",
    "3 - run CR loop to get DOIs + metadata for sample_count\n",
    "\n",
    "4 - create & run sh_blastoise on the new artcl dataset\n",
    "\n",
    "5- 100K artcl dataset is completed!\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "This nb will stay as a hub for part 5, will start step 1 in nb 5b"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92ba50c92c9dc11b366869717e90d544d23b7140e20708921d0ff91f276d2e3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
