{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this nb is to test Open Education API to get Institution info & rake-nltk for Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pdfminer.high_level import extract_text\n",
    "#import PyPDF2 as pdf2\n",
    "\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r date_df_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Massa Of Tech'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"massa of tech\".title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affilition Retrieval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Affiliation Retrieval testing, it is seen that the \"easiest\" way to extract this information is to use a Regex capture pattern from the pdf & article.\n",
    "\n",
    "Any other method needs either a tedious API process or possibly incorrect information.\n",
    "\n",
    "Therefore, 2 capture patterns will be used on the article:\n",
    "\n",
    "1- \"University name\" OR 2- \"email@address.pt\" \n",
    "\n",
    "If it's possible to extract the info from country code, ne ala, if not Uni. name can be processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('okokes@ku.edu.tr', 'ku.edu.tr', 'tr')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PART 1 - E-mail Capturing:\n",
    "\n",
    "rec_email = \"([a-zA-Z0-9._-]+@([a-zA-Z0-9._-]+\\.([a-zA-Z0-9_-]+)))\" \n",
    "\n",
    "re.findall(re.compile(rec_email, re.IGNORECASE),\"bokbo aasghdjhgas merhhaba okokes@ku.edu.tr asdghjasgdash\")\n",
    "\n",
    "#mail_found = \n",
    "#cntry_code_dict[mail_found.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ku.edu.tr'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(re.compile(rec_email, re.IGNORECASE),\"bokbo aasghdjhgas merhhaba okokes@ku.edu.tr asdghjasgdash\").group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Email regex is complete!\n",
    "\n",
    "Now to get the country info from the mail ending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntry_name_list = [cntry.name for cntry in list(pycountry.countries)]\n",
    "\n",
    "cntry_code_dict = {cntry.alpha_2 : cntry.name for cntry in list(pycountry.countries)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_code_to_country(pdftext):\n",
    "    rec_email = \"([a-zA-Z0-9._-]+@([a-zA-Z0-9._-]+\\.([a-zA-Z0-9_-]+)))\" \n",
    "    cntry_code_dict = {cntry.alpha_2 : cntry.name for cntry in list(pycountry.countries)}\n",
    "\n",
    "    ccode = re.search(re.compile(rec_email, re.IGNORECASE),pdftext).group(3)\n",
    "    if ccode == \"com\":\n",
    "        cntry_found = np.nan\n",
    "\n",
    "    else:\n",
    "        if len(ccode)>2:\n",
    "            ccode = ccode[:2]\n",
    "        cntry_found = cntry_code_dict[ccode.upper()]\n",
    "\n",
    "    return cntry_found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ED'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-cfb7a3f2e8e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# E-mail match - Option 1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfrom_code_to_country\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-222-959bf8f37a28>\u001b[0m in \u001b[0;36mfrom_code_to_country\u001b[1;34m(pdftext)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mccode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mccode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mcntry_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcntry_code_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mccode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcntry_found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ED'"
     ]
    }
   ],
   "source": [
    "# E-mail match - Option 1:\n",
    "\n",
    "from_code_to_country(pdf_read)\n",
    "\n",
    "#Fast BUT NOT!!! WORKING!!! for USA domains as they have no country code at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E-mail match - Option 2:\n",
    "\n",
    "\n",
    "email_opt2_match = re.findall(r\"(?=(\"+'|'.join(list(uni_code_country_dict.keys()))+r\"))\", pdf_read)[0]\n",
    "\n",
    "\n",
    "uni_code_country_dict[email_opt2_match]\n",
    "\n",
    "# This option REALLY slow (8-9 sec) but no need to extract any email str, loops through the entire PDF str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dpmms.cam.ac.uk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0b10d0cea76f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0memail_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"([a-zA-Z0-9._-]+@([a-zA-Z0-9._-]+\\.([a-zA-Z0-9_-]+)))\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0muni_code_country_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpdf_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'dpmms.cam.ac.uk'"
     ]
    }
   ],
   "source": [
    "# E-mail match - Option 3 - BEST!:\n",
    "email_reg = re.compile(\"([a-zA-Z0-9._-]+@([a-zA-Z0-9._-]+\\.([a-zA-Z0-9_-]+)))\" , re.IGNORECASE)\n",
    "\n",
    "uni_code_country_dict[re.search(email_reg,pdf_read).group(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Country Match - Option 1:\n",
    "re.findall(r\"(?=(\"+'|'.join(cntry_name_list)+r\"))\", pdf_read)[0][0]\n",
    "\n",
    "# This option is slower but it gives all the countries mentioned in mention order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Country Match - Option 2:\n",
    "re.search(r\"(?=(\"+'|'.join(cntry_name_list)+r\"))\", pdf_read).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Country Match - Option 3 - BEST!:\n",
    "re.search(r\"(?=(\"+'|'.join(cntry_name_list)+r\"))\", pdf_read)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belgium', 'Canada', 'Germany', 'France', 'United Kingdom', 'Georgia', 'India', 'Israel', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "# Country match - Option 4: \n",
    "str_match = [s for s in cntry_name_list if s in pdf_read]\n",
    "print(str_match)\n",
    "\n",
    "# This option is faster but it gives all the countries mentioned in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium\n"
     ]
    }
   ],
   "source": [
    "#Country match - Option 5:\n",
    "print(next((x for x in cntry_name_list if x in pdf_read), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# University Match - option 1:\n",
    "\n",
    "# same as country match opt 1, join all uni names & search in whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# University Match - option 2:\n",
    "\n",
    "# same as email match opt 3, create a regex pattern to capture uni name & the use dict or join keys to only check the captured parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Affiliation Function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://sci.bban.top/pdf/10.1007/s10658-010-9624-y.pdf#view=FitH\n"
     ]
    }
   ],
   "source": [
    "# Get a random pdf_read:\n",
    "\n",
    "random_dir_url = date_df_ok.direct_url.sample(1).values[0]\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36'}\n",
    "\n",
    "pdf_req = requests.get(random_dir_url,headers=HEADERS)\n",
    "\n",
    "print(pdf_req)\n",
    "pdf_io = io.BytesIO(pdf_req.content)\n",
    "pdf_read = extract_text(pdf_io,page_numbers=[])\n",
    "\n",
    "print(random_dir_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary dicts & lists:\n",
    "\n",
    "with open('world_universities_and_domains.json', encoding=\"utf8\") as fp:\n",
    "    uni_dict = json.load(fp)\n",
    "\n",
    "uni_df = pd.DataFrame(uni_dict)\n",
    "\n",
    "uni_code_country_dict = {}\n",
    "uni_name_country_dict = {}\n",
    "\n",
    "for index, row in uni_df.iterrows():\n",
    "    uni_code_country_dict.update({dom : row.country for dom in row.domains})\n",
    "    uni_name_country_dict.update({row[\"name\"] : row.country})\n",
    "\n",
    "del uni_name_country_dict[\"University of Technology\"]\n",
    "\n",
    "uni_name_list = list(uni_name_country_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary dicts & lists (cont.):\n",
    "\n",
    "#email_reg_original = re.compile(\"([a-zA-Z0-9._-]+@([a-zA-Z0-9._-]+\\.([a-zA-Z0-9_-]+)))\" , re.IGNORECASE)\n",
    "\n",
    "email_reg_modified = re.compile(\"[a-zA-Z0-9._-]+@([a-zA-Z0-9_-]+\\.((?:[a-zA-Z0-9_-]+\\.)*([a-zA-Z0-9_-]+)))\")\n",
    "\n",
    "cntry_name_list = [cntry.name for cntry in list(pycountry.countries)]\n",
    "cntry_name_list.append(\"USA\")\n",
    "\n",
    "cntry_name_list_all_caps = [cntry.name.upper() for cntry in list(pycountry.countries)]\n",
    "\n",
    "cntry_code_dict = {cntry.alpha_2 : cntry.name for cntry in list(pycountry.countries)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf__demo_read = \"bokbok bashdjas asdhas okokes@ku.edu.tr askdhjaskhds\"\n",
    "\n",
    "pdf_fail_read = \"ahsjdkhasd asjkdashjdh lgjknf asjdhjas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- E-Mail(Uni Domain) - DONE! :\n",
    "\n",
    "def email_converter(pdf_read):\n",
    "    email_caught = re.search(email_reg_modified,pdf_read)\n",
    "\n",
    "    try:\n",
    "        return uni_code_country_dict[email_caught.group(1).lower()]\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return uni_code_country_dict[email_caught.group(2).lower()]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                return cntry_code_dict[email_caught.group(3).upper()]\n",
    "            except KeyError:\n",
    "                cntry_pttrn =  email_caught.group(3)[:3].upper()\n",
    "\n",
    "                if cntry_pttrn in [\"COM\",\"NET\"]:\n",
    "                    return np.nan\n",
    "\n",
    "                elif cntry_pttrn in [\"EDU\",\"GOV\"]:\n",
    "                    return \"United States\"\n",
    "\n",
    "                if len(cntry_pttrn)==3:\n",
    "                    cntry_pttrn = cntry_pttrn[:-1]\n",
    "\n",
    "                try:\n",
    "                    return cntry_code_dict[cntry_pttrn]\n",
    "                except:\n",
    "                    return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_converter(pdf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Country Match - DONE:\n",
    "def country_converter(pdf_read):\n",
    "    try:\n",
    "        cntry_match = re.search(r\"(?=(\"+'|'.join(cntry_name_list)+r\"))\", pdf_read)[1]\n",
    "        return  cntry_match if cntry_match != \"USA\" else \"United States\"\n",
    "    except TypeError:\n",
    "        try:             \n",
    "            return re.search(r\"(?=(\"+'|'.join(cntry_name_list_all_caps)+r\"))\", pdf_read)[1].title()\n",
    "        except:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_converter(pdf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Scotland\" in cntry_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- University Match - DONE! :\n",
    "def univ_converter(pdf_read):   \n",
    "    try:\n",
    "        uni_found = re.search(r\"(?=(\"+'|'.join(uni_name_list)+r\"))\", pdf_read)[1]\n",
    "        return uni_name_country_dict[uni_found]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "univ_converter(pdf_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three Affiliation capture funcitons are ready! Required variables are:\n",
    "\n",
    "* \"World Unis\" json & pycountry\n",
    "* E-mail fn:\n",
    "    - email_reg_modified\n",
    "    - uni_code_country_dict\n",
    "    - country_code_dict\n",
    "* Country fn:\n",
    "    - cntry_name_list\n",
    "    - cntry_name_list_all_caps\n",
    "* Uni fn:\n",
    "    - uni_name_list\n",
    "    - uni_name_country_dict\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Affiliation Capture (OLD notes, taken care of in the final version)\n",
    "\n",
    "MUST FIX Observations from Tests:\n",
    "\n",
    "* .gmail.com emails -> COLOMBIA!\n",
    "* \"USA\" not in country list\n",
    "* email & country_match give out different results in some cases, would be very useful to have a third \"University\" field\n",
    "\n",
    "Other Noteworthy Observations:\n",
    "* Not all authors have email info, but have address written!\n",
    "* Not all first authors are working in a \"University\", but rather in a \"Institute\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World universities JSON offers info on Uni name, domain name and  country for all universities worldwide. This package therefore might be a useful for both e-mail capture & uni name capture. It will be tested below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('world_universities_and_domains.json') as fp:\n",
    "    uni_dict = json.load(fp)\n",
    "\n",
    "uni_df = pd.DataFrame(uni_dict)\n",
    "\n",
    "uni_code_country_dict = {}\n",
    "uni_name_country_dict = {}\n",
    "\n",
    "for index, row in uni_df.iterrows():\n",
    "    uni_code_country_dict.update({dom : row.country for dom in row.domains})\n",
    "    uni_name_country_dict.update({row[\"name\"] : row.country})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Turkey'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_name_country_dict[\"Koç University\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Turkey'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_code_country_dict[\"ku.edu.tr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Portugal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_code_country_dict[\"unl.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_code_country_dict[\"umn.edu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows that there are uni_codes that are seen multiple times, causing the length of the dict to be different than total codes in the JSON. One such example is rutgers.edu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "\n",
    "#unlist =uni_df.domains.tolist()\n",
    "#flatun = [item for sublist in unlist for item in sublist]\n",
    "#Counter(flatun,a)\n",
    "\n",
    "#uni_df[uni_df.domains.map(lambda x: \"rutgers.edu\" in x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scholarly - Affiliation Retr. Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly, ProxyGenerator\n",
    "\n",
    "pg = ProxyGenerator()\n",
    "success = pg.FreeProxies()\n",
    "scholarly.use_proxy(pg)\n",
    "\n",
    "search_qry = scholarly.search_author('Steven A Cholewiak')\n",
    "\n",
    "author = next(search_qry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Author',\n",
       " 'filled': [],\n",
       " 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n",
       " 'scholar_id': '4bahYMkAAAAJ',\n",
       " 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=4bahYMkAAAAJ',\n",
       " 'name': 'Steven A. Cholewiak, PhD',\n",
       " 'affiliation': 'Vision Scientist at Google LLC',\n",
       " 'email_domain': '@google.com',\n",
       " 'interests': ['Depth Cues',\n",
       "  '3D Shape',\n",
       "  'Shape from Texture & Shading',\n",
       "  'Naive Physics',\n",
       "  'Haptics'],\n",
       " 'citedby': 399}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_qry = scholarly.search_author(\"yan dongpeng\")\n",
    "author = next(search_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Author',\n",
       " 'filled': [],\n",
       " 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n",
       " 'scholar_id': 'CDfzddYAAAAJ',\n",
       " 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=CDfzddYAAAAJ',\n",
       " 'name': 'Dongpeng Yan',\n",
       " 'affiliation': 'Beijing Normal University, Beijing University of Chemical Technology',\n",
       " 'email_domain': '@bnu.edu.cn',\n",
       " 'interests': ['Materials Chemistry',\n",
       "  'Molecule Science',\n",
       "  'Chemical Engineering'],\n",
       " 'citedby': 11105}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['General Chemical Engineering', 'Environmental Engineering', 'Biotechnology']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_ok.loc[\"10.1002/aic.12400\",\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(intr in \" \".join(date_df_ok.loc[\"10.1002/aic.12400\",\"subject\"]) for intr in author[\"interests\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(x in author[\"interests\"] for x in date_df_ok.loc[\"10.1002/aic.12400\",\"subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Author',\n",
       " 'filled': [],\n",
       " 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n",
       " 'scholar_id': 'CDfzddYAAAAJ',\n",
       " 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=CDfzddYAAAAJ',\n",
       " 'name': 'Dongpeng Yan',\n",
       " 'affiliation': 'Beijing Normal University, Beijing University of Chemical Technology',\n",
       " 'email_domain': '@bnu.edu.cn',\n",
       " 'interests': ['Materials Chemistry',\n",
       "  'Molecule Science',\n",
       "  'Chemical Engineering'],\n",
       " 'citedby': 11105}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(sm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Retrieval Tests:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Using Science Parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from science_parse_api.api import parse_pdf\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://sci.bban.top/pdf/10.1002/aic.14601.pdf#view=FitH'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df_ok.loc[\"10.1002/aic.14601\",\"direct_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_req = requests.get(\"https://sci.bban.top/pdf/10.1002/aic.14601.pdf#view=FitH\")\n",
    "pdf_io = io.BytesIO(pdf_req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10585"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   # If it cannot find that folder will get the pdf and \n",
    "    # image from Github. This will occur if you are using \n",
    "    # Google Colab\n",
    "    #pdf_url = ('https://github.com/UCREL/science_parse_py_api/'\n",
    "    #           'raw/master/test_data/example_for_test.pdf')\n",
    "\n",
    "temp_test_pdf_paper = tempfile.NamedTemporaryFile('rb+')\n",
    "test_pdf_paper = Path(temp_test_pdf_paper.name)\n",
    "temp_test_pdf_paper.write(pdf_req.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test_pdf_paper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tempfile._TemporaryFileWrapper at 0x1e3d0ba1eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_pdf_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/oguzk/AppData/Local/Temp/tmpfm66jlm_')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdf_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unsupported input type: <class 'tempfile._TemporaryFileWrapper'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-04ba991133b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_test_pdf_paper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pdfminer\\high_level.py\u001b[0m in \u001b[0;36mextract_text\u001b[1;34m(pdf_file, password, page_numbers, maxpages, caching, codec, laparams)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mlaparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLAParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput_string\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBinaryIO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# we opened in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mrsrcmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPDFResourceManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaching\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pdfminer\\utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported input type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAnyIO\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unsupported input type: <class 'tempfile._TemporaryFileWrapper'>"
     ]
    }
   ],
   "source": [
    "extract_text(temp_test_pdf_paper.con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_path = Path(r\"C:\\Users\\oguzk\\NOVA\\THEsis\\Codes\\main1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\oguzk\\\\AppData\\\\Local\\\\Temp\\\\tmpfm66jlm_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-82ed8a83ab43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://127.0.0.1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'8080'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pdf_paper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\science_parse_api\\api.py\u001b[0m in \u001b[0;36mparse_pdf\u001b[1;34m(server_address, file_path, port, timeout)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{server_address}{endpoint}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     files = {'data-binary': (file_name, file_path.open('rb'), 'application/pdf',\n\u001b[0m\u001b[0;32m     47\u001b[0m                              {'Expires': '0'})}\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[0m\u001b[0;32m   1223\u001b[0m                        opener=self._opener)\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[1;34m(self, name, flags, mode)\u001b[0m\n\u001b[0;32m   1076\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0o666\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[1;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0o777\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\oguzk\\\\AppData\\\\Local\\\\Temp\\\\tmpfm66jlm_'"
     ]
    }
   ],
   "source": [
    "host = 'http://127.0.0.1'\n",
    "port = '8080'\n",
    "output_dict = parse_pdf(host, test_pdf_paper, port=port)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with test_pdf_paper.open('r') as test_fp:\n",
    "    test_fp.write(pdf_req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'empty'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Using rake_nltk\n",
    "\n",
    "There are two possible solutions to the keywords problem. One is a manual regexx pattern capture & the othehr being rake-nltk or a similar library. Depending on the performance of each one will be selected & added to sh.get_dates() pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDF_Miner\n",
    "\n",
    "with open(\"BiblTest\\main1.pdf\", 'rb') as f:\n",
    "    pdf_six = extract_text(f,page_numbers=[]).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "#PyPDF2\n",
    "\n",
    "with open(\"BiblTest\\main1.pdf\", 'rb') as f2:\n",
    "    pdf_pdf = pdf2.PdfFileReader(f2)\n",
    "    page = pdf_pdf.getPage(0)\n",
    "    page_text = page.extractText()\n",
    "    r.extract_keywords_from_text(page_text)\n",
    "    #print(page.extractText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_six_sent_tokens = sent_tokenize(pdf_six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(193.1721852014278,\n",
       "  '25 journals 7 journals 6 journals 3 social science journals 3 natural science journals one journal15 journals10 journals one journal 7 journals 14 journals 28 commercial'),\n",
       " (130.0310584070018,\n",
       "  '19971992 1985 – 1999 1997 2002 2004 2004 2005 2009 economics econometrics statistics econ ., management physics'),\n",
       " (81.31818181818181,\n",
       "  'ac ceptedche mistry engin eering biomedicine physics earth science mathema'),\n",
       " (71.49940982682381, '1577 /$ – see front matter © http :// dx'),\n",
       " (69.82727272727273,\n",
       "  'analytical chemistry geoscience mainly engineering agriculture biomedicine civil engineering cross'),\n",
       " (61.21734410198315,\n",
       "  'two conventional 26 iranian journals 1980 1986 – 1990 1994'),\n",
       " (51.1, 'revised form 3 september 2013accepted 4 september 2013keywords'),\n",
       " (47.56033724340177,\n",
       "  'acceptdiscipline journal size journal article × size discipline total 3'),\n",
       " (44.26774465080917,\n",
       "  'publishdiscipline journal size journal article × size discipline total 5'),\n",
       " (42.66953763277583, 'publishingin open access journals (“ gold oa ”)'),\n",
       " (37.92090575477597,\n",
       "  '914 – 923917table 1previous studies concerning publication delays'),\n",
       " (37.8733153638814,\n",
       "  '2013 ). shtnom15129630d accepted tolishepub received toaccepted fig'),\n",
       " (34.16666666666667, 'press ” usually without exact page numbers'),\n",
       " (32.13781055900621,\n",
       "  'scholarly peer reviewed journals usually entails long delays'),\n",
       " (31.89532520325203, 'full article status via post publication feedback'),\n",
       " (30.25, 'get thenecessary copies via interlibrary loan'),\n",
       " (30.0, 'completely copy editedand formatted “ ahead'),\n",
       " (29.547619047619047, 'pearson product moment correlation − 0'),\n",
       " (28.9, 'ideally go back around 25 years'),\n",
       " (28.615716908321158,\n",
       "  'rising publication delays inﬂate journal impact factors'),\n",
       " (28.603658536585364, 'publication date unless stated speciﬁcally wasbased'),\n",
       " (27.3739837398374,\n",
       "  'traditional paper publishing inparticular creates signiﬁcant delays'),\n",
       " (26.73846153846154, 'variance percent variance percenttable 3 presents'),\n",
       " (26.65, 'dissemination thatthe traditional subscription model achieves'),\n",
       " (25.982474301696268,\n",
       "  'electronic open access journals publish articles directly'),\n",
       " (25.50333333333333, 'authorstaking excessively long times making revisions'),\n",
       " (25.450310559006212, 'three civil engineering journals reported'),\n",
       " (24.75, 'freely available abstracts included sufﬁcient informationon'),\n",
       " (23.868457445871428, '1 – 2 ), http :// dx'),\n",
       " (23.669811320754718, '914 – 923915the solution proposed'),\n",
       " (23.650310559006215, '14 selected food research journals'),\n",
       " (23.605072463768117, 'speciﬁc journals .© 2013 elsevier ltd'),\n",
       " (23.527896765902764, 'handful oa journals contained exact date'),\n",
       " (23.488858939802338, '3 ), 642 – 650'),\n",
       " (23.488858939802338, '3 ), 259 – 274'),\n",
       " (23.438697318007662, 'articles (“ green oa ”)'),\n",
       " (23.3125, 'socially shapedwithin narrow scholarly communities'),\n",
       " (22.605072463768117,\n",
       "  'manuscript undergoes varies considerably across journals'),\n",
       " (22.541666666666668, 'usaart iclei nfoabstract article history'),\n",
       " (22.518181818181816, 'three natural science'),\n",
       " (22.284848484848485, 'cs social science arts andhumani'),\n",
       " (22.18709721650898, 'study also differs fromall earlier studies'),\n",
       " (21.42929292929293, 'science commercial publishers'),\n",
       " (21.20967741935484, 'almost de facto standard journal policy'),\n",
       " (21.180555555555557, 'intensive process butprovides precise statistics'),\n",
       " (21.169811320754718, '914 – 923contents lists available'),\n",
       " (21.158643892339548, 'gain accesswere smaller journals published'),\n",
       " (21.125, 'table 2 presents summary statistics'),\n",
       " (21.090710115055046, '914 – 923921open access journals'),\n",
       " (20.916666666666668, 'highest classiﬁcation included only4 categories'),\n",
       " (20.5, 'rule excluding parallel submissionis understandable'),\n",
       " (20.42179005989748,\n",
       "  'study included journals period studied discipline delay'),\n",
       " (20.27777777777778, 'smallmemdiu large 920b .- c'),\n",
       " (20.228634850166483, '914 – 923table 3time submission'),\n",
       " (20.228634850166483, '914 – 923919table 2time submission'),\n",
       " (20.188858939802337, '4 ), 262 – 266'),\n",
       " (20.095765104460757, 'spectrum economics andstatistics journals typically'),\n",
       " (20.05, 'main studythe main source database'),\n",
       " (20.038858939802335, '2 ), 121 – 129'),\n",
       " (19.950310559006212, 'randomly selected 100 journals indexed'),\n",
       " (19.93181818181818, 'hand also imply challenges inﬁnding'),\n",
       " (19.80961791831357, 'acceptance since smaller journals may appear'),\n",
       " (19.788858939802335, '1 ), 98 – 107'),\n",
       " (19.751344086021504, 'elevated tofull journal article status'),\n",
       " (19.595787545787545,\n",
       "  'acceptance timesis among individual manuscripts within'),\n",
       " (19.321428571428573, 'multiple simultaneous submissions ofa manuscript'),\n",
       " (19.20967741935484, 'journal though theywere fairly modest'),\n",
       " (19.150000000000002, 'revisions typically required bythe editor'),\n",
       " (19.128207324908974, 'oa journals differfrom subscription journals'),\n",
       " (19.06197309002358, '45 journals per size group'),\n",
       " (18.77777777777778, 'selected 20 articles working backward'),\n",
       " (18.538461538461537, 'benchmarking studies within narrow disciplines'),\n",
       " (18.52351155156204, 'size group andarticles within journals'),\n",
       " (18.469169719169717, 'peer reviewed articles published per year'),\n",
       " (18.353658536585364, 'acceptanceto publication lag increased somewhat'),\n",
       " (18.196266347209743, '5 ), 95 – 101'),\n",
       " (18.05031055900621, 'bmc journalswith eleven society journals'),\n",
       " (17.866666666666667, 'second level includes 27 categories'),\n",
       " (17.76920634920635, 'acceptance times since articles might go'),\n",
       " (17.541666666666668, 'pilot studybefore starting data collection'),\n",
       " (17.5, 'clearly unsuitable without sendingthem'),\n",
       " (17.416666666666668, 'provides freely accessible scopus data'),\n",
       " (17.33360904328646, '20 articles per journal resultingin'),\n",
       " (17.32429429884361, '26 iranian journals publishing'),\n",
       " (17.25231707317073, 'publishing times across various ﬁelds'),\n",
       " (17.216977225672878, '28 12 journals'),\n",
       " (17.19871794871795, 'alternative peer review model practiced'),\n",
       " (17.196153846153848, 'source normalized impact per paper'),\n",
       " (16.916666666666664, 'important factor affectingauthors ’ choice'),\n",
       " (16.913401064344463, '9 – 28'),\n",
       " (16.356410256410257, '2012 12 11 stm report 2012'),\n",
       " (16.31904761904762, '3 ), paper 255'),\n",
       " (16.236596736596738, 'may include long review processes'),\n",
       " (16.0, 'minimal reviewand subsequently evaluated'),\n",
       " (15.829032258064517, '3 journal size groupings'),\n",
       " (15.722773642128482, '900 articles per size group'),\n",
       " (15.6, 'psjournalm3trics research analytics redeﬁned'),\n",
       " (15.512820512820513, 'high per page cost'),\n",
       " (15.5, 'received 20 july 2013received'),\n",
       " (15.393156633722672, 'table 1 ). two factors'),\n",
       " (15.3125, 'scholarly publishingreview timeprocessing timepublishing'),\n",
       " (15.0, 'usuallyused small convenience samples'),\n",
       " (14.836477987421382, 'ams publ1452 – 1456'),\n",
       " (14.700310559006212, 'many journals screen submissions'),\n",
       " (14.55031055900621, 'studied 14 journals'),\n",
       " (14.503762078994278, 'created open access months submitted'),\n",
       " (14.5, 'interpreted witha great deal'),\n",
       " (14.455525606469003, '1970 – 1999 ),'),\n",
       " (14.287878787878789, 'separate groups ofresearchers may'),\n",
       " (14.278195488721805, '9780262517638 open accesspdf version'),\n",
       " (14.25, 'evenly distributed across disciplines'),\n",
       " (14.181818181818182, 'periodicals price survey 2002'),\n",
       " (14.166666666666666, 'long history going back'),\n",
       " (14.075310559006212, 'reviewed journals across disciplines'),\n",
       " (14.005866114561766, 'two conventional journals'),\n",
       " (14.0, 'predominantly digitally distributed pub'),\n",
       " (14.0, '1 517 339 0720'),\n",
       " (13.974974200206399, 'growth among open access'),\n",
       " (13.950310559006212, 'mathematics andengineering journals tending'),\n",
       " (13.86111111111111, 'thetwo biggest publishers elsevier'),\n",
       " (13.836021505376346, 'among disciplinesand size groups'),\n",
       " (13.77450980392157, '“ feasibility study ”'),\n",
       " (13.708333333333334, '“ published ” prior'),\n",
       " (13.700310559006212, 'submit tocompeting journals simultaneously'),\n",
       " (13.636363636363637, 'publicationtimes may also reﬂect'),\n",
       " (13.575, 'particular concerned three aspects'),\n",
       " (13.566666666666666, 'currently publishes around 20'),\n",
       " (13.523809523809524, '2000had reduced average delays'),\n",
       " (13.5, 'unpaid referee work done'),\n",
       " (13.5, 'strong bias toward jour'),\n",
       " (13.5, '202 e fee hall'),\n",
       " (13.458333333333334, 'obtain complete data across'),\n",
       " (13.41923076923077, 'table 4estimated variance components'),\n",
       " (13.344249952945605, 'chemistry journals achieving delays'),\n",
       " (13.333333333333334, 'economicsand michigan state university'),\n",
       " (13.3, '3 14'),\n",
       " (13.260220125786164, 'doaj ). data management'),\n",
       " (13.23611111111111, 'ideally publishers would track'),\n",
       " (13.225, 'constant across different ﬁelds'),\n",
       " (13.21282207344289, 'sjr – scimago journal'),\n",
       " (13.184537684537684, '300 articles per discipline'),\n",
       " (13.177583286278939, 'analytical chemistry journals'),\n",
       " (13.164222873900293, 'journal may still publish'),\n",
       " (13.162431771127423, 'ﬁve leading economics journals'),\n",
       " (13.160919540229886, 'oa “ megajournals ”'),\n",
       " (13.154761904761905, '001 2013 elsevier ltd'),\n",
       " (13.118181818181819, 'predominantly social science'),\n",
       " (13.111111111111112, '20 articles perjournal resulting'),\n",
       " (13.06060606060606, 'chemistry atmospheric sciencesphysical sciences'),\n",
       " (13.055555555555555, 'thus speeding upthe process'),\n",
       " (13.0, 'yearly averages ranging between6'),\n",
       " (12.959677419354838, 'choice journal potentially rendering'),\n",
       " (12.944444444444445, 'articles ’ face page'),\n",
       " (12.92947722567288, 'iranian scholarly journals'),\n",
       " (12.908643892339544, 'biomedical journals varies due'),\n",
       " (12.902896765902764, 'high quality oa journals'),\n",
       " (12.833333333333334, 'determine whichgroup gains credit'),\n",
       " (12.804195804195805, '9 discipline categories resulting'),\n",
       " (12.75, 'paper contains detailed breakdowns'),\n",
       " (12.73022508892074, 'variation among journals within'),\n",
       " (12.708333333333334, 'enough data availableto make'),\n",
       " (12.702051282051283, 'theaverage review times vary'),\n",
       " (12.700310559006212, '25 journals'),\n",
       " (12.694252873563219, 'leading oa publisher biomedcentral'),\n",
       " (12.690403799099451, '15 journals per discipline'),\n",
       " (12.681079789775442, '26 7 journals'),\n",
       " (12.631436314363144, 'publication 922b .- c'),\n",
       " (12.615384615384615, 'successful thanopen review experiments'),\n",
       " (12.583333333333334, 'new reviewers get involved'),\n",
       " (12.535384615384615, 'review times among submissions'),\n",
       " (12.533333333333333, 'results ofthe research outdated'),\n",
       " (12.373015873015873, 'peer b .- c'),\n",
       " (12.371212121212121, 'particular article may reﬂect'),\n",
       " (12.31904761904762, '3 ), 379'),\n",
       " (12.315604000513616, 'open access journal using'),\n",
       " (12.313186813186814, 'david solomon b ,∗'),\n",
       " (12.11111111111111, '135 journalsand 2700 articles'),\n",
       " (12.023658536585366, 'publication times nearly twice'),\n",
       " (12.0, 'de facto determiner'),\n",
       " (12.0, 'citation rates across disciplines'),\n",
       " (11.982404692082111, 'one journal categorywhere'),\n",
       " (11.976190476190476, 'even longer since manymanuscripts'),\n",
       " (11.950000000000001, 'extracted article level data'),\n",
       " (11.927899686520377, 'oa one oa'),\n",
       " (11.916666666666668, 'since citation rate isat'),\n",
       " (11.898656898656899, 'b .- c .,'),\n",
       " (11.885836385836386, '000 articles per year'),\n",
       " (11.875, 'detailed summary statistics'),\n",
       " (11.836477987421384, 'period1985 – 1999'),\n",
       " (11.829598506069093, 'http :// dx'),\n",
       " (11.829598506069093, 'http :// dx'),\n",
       " (11.829598506069093, 'http :// dx'),\n",
       " (11.829598506069093, 'http :// dx'),\n",
       " (11.829598506069093, 'http :// dx'),\n",
       " (11.781818181818181, 'also involve several cycles'),\n",
       " (11.768492377188029, 'threesocial science journals'),\n",
       " (11.755866114561767, 'variation among journals accounted'),\n",
       " (11.669811320754718, '914 – 923submission'),\n",
       " (11.669811320754718, '914 – 923periods'),\n",
       " (11.669811320754718, '914 – 923in'),\n",
       " (11.669811320754718, '914 – 923923suber'),\n",
       " (11.616977225672876, 'random sample covering journals'),\n",
       " (11.6, 'ﬁve different key points'),\n",
       " (11.575310559006212, 'six statistics journals'),\n",
       " (11.569811320754717, '4 – 6'),\n",
       " (11.555555555555555, 'last item could often'),\n",
       " (11.5, 'country rank web site'),\n",
       " (11.421602787456445, 'publishing .∗ corresponding author'),\n",
       " (11.34716503009186, 'average total publication delay'),\n",
       " (11.285050048081125, 'scholarly journal publishing process'),\n",
       " (11.231126596980255, 'studied average publishing delays'),\n",
       " (11.217430368373766, '0 – 26'),\n",
       " (11.2, 'relative steady 3'),\n",
       " (11.192307692307693, 'mit press ., available'),\n",
       " (11.169811320754718, '93 – 100'),\n",
       " (11.169811320754718, '1 – 6'),\n",
       " (11.137810559006212, 'reviewed scholarly journals'),\n",
       " (11.135039623045621, 'compared six oa journals'),\n",
       " (11.125, 'generalizability theory statistics'),\n",
       " (10.991977225672876, 'peer reviewed journals'),\n",
       " (10.961501673840267, 'thisto study publication delays'),\n",
       " (10.950310559006212, 'almost entirelyamong journals'),\n",
       " (10.854166666666666, 'scholarly article undergoes'),\n",
       " (10.841951425879277, 'open access journals'),\n",
       " (10.841951425879277, 'open access journals'),\n",
       " (10.818181818181818, 'earth science'),\n",
       " (10.816919191919192, 'total delay would often'),\n",
       " (10.775, 'different engineering ﬁelds'),\n",
       " (10.65967741935484, 'ﬁrst time period reﬂects'),\n",
       " (10.619047619047619, '2005 ),'),\n",
       " (10.569358178053829, 'closes ), journals'),\n",
       " (10.563335955940204, 'total time submissionto publication'),\n",
       " (10.55031055900621, 'typically top journals'),\n",
       " (10.529761904761905, 'clear differences among ﬁelds'),\n",
       " (10.513831696758526, 'periodical average publication delay'),\n",
       " (10.5, 'generally copy edited'),\n",
       " (10.283643892339544, 'larger journals appear'),\n",
       " (10.283643892339544, 'include datafrom journals'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// www'),\n",
       " (10.258169934640524, 'http :// washburnlaw'),\n",
       " (10.258169934640524, 'http :// mitpress'),\n",
       " (10.258169934640524, 'http :// informationr'),\n",
       " (10.25, 'generally consistent across'),\n",
       " (10.237373737373737, 'often also provide information'),\n",
       " (10.196078431372548, 'libraries ’ electronic holdings'),\n",
       " (10.18962839392545, 'scholarly publishing –'),\n",
       " (10.169811320754718, '947 – 993'),\n",
       " (10.169811320754718, '305 – 307'),\n",
       " (10.169811320754718, '271 – 286'),\n",
       " (10.169811320754718, '12429 – 40'),\n",
       " (10.169811320754718, '1050 – 1055'),\n",
       " (10.116977225672876, 'editorsof 20 journals'),\n",
       " (10.091977225672878, 'journals typically published'),\n",
       " (10.035714285714285, 'factors inﬂuencing choice'),\n",
       " (10.01818181818182, 'information systems science'),\n",
       " (10.0, 'journalswith broader scopes'),\n",
       " (10.0, 'freely downloadable spreadsheet'),\n",
       " (9.985275593971245, 'journals within discipline'),\n",
       " (9.950310559006212, 'seven studied journals'),\n",
       " (9.950310559006212, 'larger journals appearing'),\n",
       " (9.950310559006212, 'highly cited journals'),\n",
       " (9.950310559006212, 'called predatory journals'),\n",
       " (9.948199599142995, '0 – 7'),\n",
       " (9.900580551523948, '7 – 31'),\n",
       " (9.883333333333335, 'determining born vs converted'),\n",
       " (9.875, 'mean number mean std'),\n",
       " (9.86911397780963, 'articles within journals'),\n",
       " (9.86911397780963, 'articles within journals'),\n",
       " (9.833333333333334, 'headings like “'),\n",
       " (9.833333333333332, 'excessively long reviewperiods'),\n",
       " (9.777896765902764, 'journals createdas oa'),\n",
       " (9.777896765902764, 'fullyelectronic oa journals'),\n",
       " (9.757723408666806, '7 – 18'),\n",
       " (9.75438596491228, 'open webrepositories prior'),\n",
       " (9.75, 'acceptmanuscripts pending revisions'),\n",
       " (9.74388539482879, '5 – 20'),\n",
       " (9.737096237096237, '9 month average delay'),\n",
       " (9.736477987421383, '4 – 20'),\n",
       " (9.727859237536657, 'information science journal'),\n",
       " (9.677583286278939, 'ten chemistry journals'),\n",
       " (9.677583286278939, 'journals withineach discipline'),\n",
       " (9.652777777777777, 'peer reviewed articles'),\n",
       " (9.65, 'table 4 contains'),\n",
       " (9.636363636363637, 'also may reﬂect'),\n",
       " (9.632128740824392, 'also thetraditional journals'),\n",
       " (9.619047619047619, '2004 ),'),\n",
       " (9.618181818181817, 'social science'),\n",
       " (9.618181818181817, 'social science'),\n",
       " (9.61111111111111, 'https :// scholarworks'),\n",
       " (9.6, 'approximately 14'),\n",
       " (9.598957940043796, 'open access publishing'),\n",
       " (9.598957940043796, 'open access publishing'),\n",
       " (9.598957940043796, 'open access publishing'),\n",
       " (9.577218728162125, '5 – 36'),\n",
       " (9.561033169728823, 'delay within journals'),\n",
       " (9.541666666666666, 'almost exclusively published'),\n",
       " (9.509677419354837, 'large journal strata'),\n",
       " (9.502136752136753, 'among articles within'),\n",
       " (9.5, 'ensuing rapid growth'),\n",
       " (9.495765104460755, 'major economics journals'),\n",
       " (9.422532781228433, 'variation among journals'),\n",
       " (9.4, 'main outcome variables'),\n",
       " (9.39902850772416, 'peer review journals'),\n",
       " (9.37292960662526, 'journals using data'),\n",
       " (9.353658536585366, 'publication processes whenconsidering'),\n",
       " (9.346281908990012, '8 – 34'),\n",
       " (9.346281908990012, '8 – 34'),\n",
       " (9.336477987421384, '20 – 30'),\n",
       " (9.333333333333334, 'michigan state university'),\n",
       " (9.333333333333334, 'michigan state university'),\n",
       " (9.333333333333332, 'long delays involved'),\n",
       " (9.3125, 'whole scholarly community'),\n",
       " (9.30188679245283, '2005 ).'),\n",
       " (9.285714285714285, 'aremany idiosyncratic factors'),\n",
       " (9.283643892339544, 'ﬁxed effectswhile journals'),\n",
       " (9.277777777777779, '918b .- c'),\n",
       " (9.277777777777779, '916b .- c'),\n",
       " (9.257264957264958, 'articles per strata'),\n",
       " (9.25, 'ability toobtain copies'),\n",
       " (9.219047619047618, '12 ), e53374'),\n",
       " (9.208333333333332, 'published electronically ahead'),\n",
       " (9.207317073170731, 'traditional print publishing'),\n",
       " (9.207317073170731, 'publishing fee variant'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.206349206349206, 'b .- c'),\n",
       " (9.1869918699187, 'publication varies signiﬁcantly'),\n",
       " (9.177896765902762, 'journals created oa'),\n",
       " (9.177218728162124, '5 – 12'),\n",
       " (9.169811320754718, '37 – 43'),\n",
       " (9.158643892339544, 'law journals published'),\n",
       " (9.116977225672876, '15 leadinginternational journals'),\n",
       " (9.11111111111111, 'individual journalsand articles'),\n",
       " (9.083333333333334, 'made aconscious choice'),\n",
       " (9.055555555555555, 'past two centuries'),\n",
       " (9.0, 'tort et al'),\n",
       " (9.0, 'tedious work ofacknowledgementsgathering'),\n",
       " (9.0, 'subjector institutional repositories'),\n",
       " (9.0, 'shortterm bibliometric comparisons'),\n",
       " (9.0, 'shortest overalldelays occur'),\n",
       " (9.0, 'publish around 12'),\n",
       " (9.0, 'many ways andafter'),\n",
       " (9.0, 'individual scholarsand retard'),\n",
       " (9.0, 'increasingly entered thismarket'),\n",
       " (9.0, 'disseminated indigital form'),\n",
       " (9.0, 'avoiding unnecessary replication'),\n",
       " (9.0, 'allowing authorsthe possibility'),\n",
       " (9.0, '2700 articlesmonths submitted'),\n",
       " (8.977896765902763, 'oa journals rather'),\n",
       " (8.975186104218363, 'journal size group'),\n",
       " (8.954545454545455, 'part may reﬂect'),\n",
       " (8.950310559006212, 'ﬁnd alternative journals'),\n",
       " (8.950310559006212, 'physics journals'),\n",
       " (8.950310559006212, '135 journals sampled'),\n",
       " (8.945054945054945, 'studies using statisticssolicited'),\n",
       " (8.933333333333334, 'quickly manuscripts go'),\n",
       " (8.891640866873065, '19 open access'),\n",
       " (8.857142857142858, 'parallel paper version'),\n",
       " (8.857142857142858, 'parallel paper version'),\n",
       " (8.833333333333332, 'disclose long delays'),\n",
       " (8.76923076923077, 'partitionthe variance associated'),\n",
       " (8.753689316397418, '5 – 8'),\n",
       " (8.75, '25'),\n",
       " (8.729722323712092, 'born electronic journals'),\n",
       " (8.72949449252557, 'scholarly journal publishing'),\n",
       " (8.72949449252557, 'scholarly journal publishing'),\n",
       " (8.72949449252557, 'scholarly journal publishing'),\n",
       " (8.709677419354838, 'journal page limits'),\n",
       " (8.702218728162125, '5 – 17'),\n",
       " (8.67141541198145, '5 months ). kling'),\n",
       " (8.666666666666666, 'minimize unnecessary delays'),\n",
       " (8.666666666666666, 'latter usually means'),\n",
       " (8.666666666666666, 'henry oldenburg ’'),\n",
       " (8.666666666666666, 'delays slowthe dissemination'),\n",
       " (8.636363636363637, 'total delay sub'),\n",
       " (8.619047619047619, 'physics ),'),\n",
       " (8.61111111111111, 'publish articles individually'),\n",
       " (8.61111111111111, 'publish articles considerably'),\n",
       " (8.6, 'different subject areas'),\n",
       " (8.6, 'bmc journalsclearly outperformed'),\n",
       " (8.59620596205962, 'publishing process prior'),\n",
       " (8.555555555555555, 'offersfor process innovation'),\n",
       " (8.550763701707098, '0 – 11'),\n",
       " (8.544811320754718, '2 – 17'),\n",
       " (8.544811320754718, '2 – 17'),\n",
       " (8.541666666666668, 'much smaller number'),\n",
       " (8.533333333333333, 'amongother information provides'),\n",
       " (8.509677419354837, 'smallest journal strata'),\n",
       " (8.5, 'print ” versions'),\n",
       " (8.5, 'journalm3trics web site'),\n",
       " (8.5, 'international association ofscientiﬁc'),\n",
       " (8.5, 'email communication widely'),\n",
       " (8.5, 'called ingleﬁnger rule'),\n",
       " (8.450310559006212, 'traditional journals'),\n",
       " (8.450310559006212, 'selective journals particularly'),\n",
       " (8.450310559006212, 'available journals contained'),\n",
       " (8.448717948717949, 'peer review trial'),\n",
       " (8.448717948717949, 'external peer review'),\n",
       " (8.423963133640553, 'journal using averages'),\n",
       " (8.41699449252557, 'introductionscholarly journal publishing'),\n",
       " (8.4, 'revision request wasmade'),\n",
       " (8.39149560117302, 'journal also publishes'),\n",
       " (8.375, 'data collected formed'),\n",
       " (8.373983739837398, 'causes publishing delays'),\n",
       " (8.369047619047619, '2011 ), proving'),\n",
       " (8.346281908990012, '8 – 1'),\n",
       " (8.333333333333334, 'turn ofthe millennium'),\n",
       " (8.333333333333334, 'second world war'),\n",
       " (8.333333333333334, 'post “'),\n",
       " (8.333333333333332, 'leading us universities'),\n",
       " (8.329032258064515, 'journal size level'),\n",
       " (8.318181818181818, 'food science'),\n",
       " (8.30188679245283, '2004 ).'),\n",
       " (8.30188679245283, '2004 ).'),\n",
       " (8.282051282051281, 'review andpublishing cultures'),\n",
       " (8.274509803921568, 'pilot study conﬁrmed'),\n",
       " (8.273658536585366, 'theshortest publication times'),\n",
       " (8.272727272727273, 'plos one'),\n",
       " (8.272727272727273, 'plos one'),\n",
       " (8.272727272727273, 'plos one'),\n",
       " (8.272727272727273, 'plos one'),\n",
       " (8.25, 'previously published data'),\n",
       " (8.25, 'authors vary greatly'),\n",
       " (8.236728837876614, 'electronic publishing becoming'),\n",
       " (8.231126596980255, 'average publishing delays'),\n",
       " (8.23076923076923, 'empirical studies could'),\n",
       " (8.217430368373766, '0 – 29'),\n",
       " (8.212121212121211, 'delays inthe economics'),\n",
       " (8.209677419354838, 'largest journal stratathough'),\n",
       " (8.208333333333334, 'supplementary data associated'),\n",
       " (8.208333333333334, 'makethis data available'),\n",
       " (8.194444444444445, 'independence among articles'),\n",
       " (8.180555555555555, 'addressed two issues'),\n",
       " (8.169230769230769, 'true variance components'),\n",
       " (8.152777777777779, 'articles published electronically'),\n",
       " (8.130801393728223, 'average publication times'),\n",
       " (8.130801393728223, 'average publication times'),\n",
       " (8.125, 'scopus citation index'),\n",
       " (8.125, 'scopus citation index'),\n",
       " (8.11111111111111, 'econometrics articles'),\n",
       " (8.107142857142858, 'version 2 citationmeasures'),\n",
       " (8.1, '3 4'),\n",
       " (8.071428571428571, 'uploading manuscript versions'),\n",
       " (8.052272727272728, '10 statistics based'),\n",
       " (8.043010752688172, 'total time increased'),\n",
       " (8.043010752688172, 'journal ofatmospheric sciences'),\n",
       " (8.041666666666666, 'individual article reviews'),\n",
       " (8.040650406504065, 'publishing working papers'),\n",
       " (8.019047619047619, '4 ), e115'),\n",
       " (8.010347376201034, 'ithe publishing delay'),\n",
       " (8.008333333333333, 'provide overall data'),\n",
       " (8.004273504273504, 'peer review process'),\n",
       " (8.004273504273504, 'peer review process'),\n",
       " (8.004273504273504, 'peer review process'),\n",
       " (8.0, 'yu et al'),\n",
       " (8.0, 'mainly attributable'),\n",
       " (8.0, 'larger editorial staff'),\n",
       " (8.0, 'doesnot seem surprising'),\n",
       " (7.958333333333334, 'quality might lengthen'),\n",
       " (7.955555555555556, 'revision process unacceptable'),\n",
       " (7.948717948717948, 'washburn law review'),\n",
       " (7.925, 'would provide alevel'),\n",
       " (7.92, 'four times ayear'),\n",
       " (7.916666666666666, 'scopus article counts'),\n",
       " (7.912121212121212, '3 months'),\n",
       " (7.869047619047619, '2 ), ellison'),\n",
       " (7.853658536585366, 'since publication delays'),\n",
       " (7.846041055718476, 'total delay time'),\n",
       " (7.843010752688172, 'middle journal strata'),\n",
       " (7.825310559006211, 'journals would need'),\n",
       " (7.825, '17 3'),\n",
       " (7.814814814814815, '5 monthsto 5'),\n",
       " (7.808327174180833, 'economics publishing process'),\n",
       " (7.803030303030303, 'mathematical physicsa delay'),\n",
       " (7.79296066252588, 'björk ), dsolomon'),\n",
       " (7.769230769230769, 'estimated variance components1'),\n",
       " (7.753787878787879, 'published months submitted'),\n",
       " (7.753787878787879, 'published months submitted'),\n",
       " (7.75, 'authors whose work'),\n",
       " (7.709677419354839, 'reducing time totort'),\n",
       " (7.709677419354839, 'key time points'),\n",
       " (7.708333333333334, 'rapidly developing ﬁelds'),\n",
       " (7.686274509803921, '8 vs 8'),\n",
       " (7.678030303030303, 'collected delay data'),\n",
       " (7.666666666666667, 'khosrowjerdi et al'),\n",
       " (7.666666666666667, 'dong et al'),\n",
       " (7.666666666666667, 'dióspatonyi et al'),\n",
       " (7.666666666666666, 'result inlong delays'),\n",
       " (7.62, 'ﬁrst response times'),\n",
       " (7.607142857142858, '18 monthstook twice'),\n",
       " (7.6068181818181815, 'would also provide'),\n",
       " (7.6, 'medical internet research'),\n",
       " (7.560606060606061, 'latter groups based'),\n",
       " (7.5588235294117645, 'choose topublish submission'),\n",
       " (7.541666666666666, 'scientiﬁc ﬁelds advance'),\n",
       " (7.533643892339544, 'among journals'),\n",
       " (7.52, 'cases several times'),\n",
       " (7.519887955182073, 'electronic version manuscripts'),\n",
       " (7.513831696758526, 'average publication delay'),\n",
       " (7.5, 'w w w'),\n",
       " (7.5, 'usually though'),\n",
       " (7.5, 'since snip values'),\n",
       " (7.5, 'press ”'),\n",
       " (7.5, 'position inthe queue'),\n",
       " (7.5, 'dumville ,& petherickbritish'),\n",
       " (7.5, 'centric view looking'),\n",
       " (7.5, 'applied econometrics'),\n",
       " (7.462121212121212, '2 months in1994'),\n",
       " (7.459677419354838, 'journal web sites'),\n",
       " (7.450310559006211, 'journals indexed'),\n",
       " (7.4411764705882355, 'study comparing subscriptionjournals'),\n",
       " (7.416666666666666, 'gather article data'),\n",
       " (7.378787878787879, 'accepted months accepted'),\n",
       " (7.378787878787879, 'accepted months accepted'),\n",
       " (7.375, 'particular physics'),\n",
       " (7.375, 'achieved viaa number'),\n",
       " (7.3503105590062106, 'subscription journals'),\n",
       " (7.3503105590062106, 'subscription journals'),\n",
       " (7.3503105590062106, 'subscription journals'),\n",
       " (7.345454545454546, 'social economics'),\n",
       " (7.333333333333334, 'increased critique since'),\n",
       " (7.333333333333333, 'edu /∼ dennis'),\n",
       " (7.3088235294117645, 'web submission systems'),\n",
       " (7.282051282051282, 'original review cycle'),\n",
       " (7.273658536585366, 'publication times appears'),\n",
       " (7.262810559006211, 'scholarly journals'),\n",
       " (7.258002866698519, 'journals within'),\n",
       " (7.212121212121212, '6 months'),\n",
       " (7.212121212121212, '6 months'),\n",
       " (7.208333333333334, 'ﬁelds might ﬁnd'),\n",
       " (7.2, 'wechecked ﬁrst whether'),\n",
       " (7.193181818181818, 'science ﬁelds'),\n",
       " (7.1869918699187, 'current publication lags'),\n",
       " (7.1764705882352935, '8 6'),\n",
       " (7.166666666666666, 'ﬁnal publicationas part'),\n",
       " (7.166666666666666, 'stratiﬁed random sample'),\n",
       " (7.133333333333333, 'social sciences'),\n",
       " (7.133333333333333, 'social sciences'),\n",
       " (7.133333333333333, 'social sciences'),\n",
       " (7.125, 'obtained statistics'),\n",
       " (7.083333333333334, 'world wide web'),\n",
       " (7.074999999999999, 'mean number 4'),\n",
       " (7.063335955940205, 'publication time associated'),\n",
       " (7.0588235294117645, 'havemuch faster submission'),\n",
       " (7.053470919324578, 'nature publishing group'),\n",
       " (7.0181818181818185, 'information science'),\n",
       " (7.0181818181818185, 'information science'),\n",
       " (7.0, 'signiﬁcant back'),\n",
       " (7.0, 'including bundled e'),\n",
       " (6.980769230769231, 'previous studies point'),\n",
       " (6.958333333333334, 'analysis ofthe breakdown'),\n",
       " (6.950310559006211, 'multiple journals'),\n",
       " (6.950310559006211, 'multiple journals'),\n",
       " (6.950310559006211, '135 journals'),\n",
       " (6.950310559006211, '000 journals'),\n",
       " (6.95, '3 23'),\n",
       " (6.9411764705882355, 'multiple case study'),\n",
       " (6.933333333333334, 'quickly reject manuscripts'),\n",
       " (6.891640866873065, 'open access'),\n",
       " (6.891640866873065, 'open access'),\n",
       " (6.883070301291248, 'electronic publication offers'),\n",
       " (6.881818181818182, 'also obtained information'),\n",
       " (6.8774680603948894, 'compared publication delays'),\n",
       " (6.859523809523809, 'accepted manuscripts even'),\n",
       " (6.833333333333333, 'excessively long'),\n",
       " (6.812698412698413, 'revision process used'),\n",
       " (6.8, 'social informatics'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.777896765902763, 'oa journals'),\n",
       " (6.764008004574042, '2 months ).'),\n",
       " (6.75, 'usually included'),\n",
       " (6.708333333333334, 'get data'),\n",
       " (6.7018867924528305, '1997 ).'),\n",
       " (6.700310559006211, 'included journals'),\n",
       " (6.686502177068215, 'solomon ). 1751'),\n",
       " (6.666666666666668, 'middle third made'),\n",
       " (6.666666666666667, '1999 1970'),\n",
       " (6.660848079069026, 'electronic publication dates'),\n",
       " (6.616977225672878, 'ams journals'),\n",
       " (6.59093108149712, '9 months ).'),\n",
       " (6.568181818181818, 'science authors'),\n",
       " (6.566820276497696, 'time windows used'),\n",
       " (6.5588235294117645, 'considerably shorter submission'),\n",
       " (6.555555555555555, 'u r n'),\n",
       " (6.550310559006212, 'bmc journals'),\n",
       " (6.5, 'stm report'),\n",
       " (6.5, 'freely available'),\n",
       " (6.5, 'example february 15th'),\n",
       " (6.5, 'decision concerning'),\n",
       " (6.5, 'checked via'),\n",
       " (6.495765104460757, 'economics journals'),\n",
       " (6.495765104460757, 'economics journals'),\n",
       " (6.492307692307692, 'g ., yu'),\n",
       " (6.491666666666666, 'scientiﬁc quality level'),\n",
       " (6.484848484848485, 'science technology'),\n",
       " (6.479166666666666, 'scholarly peer'),\n",
       " (6.479166666666666, 'scholarly peer'),\n",
       " (6.476190476190476, 'acceptance vs acceptance'),\n",
       " (6.4573170731707314, 'publishing model'),\n",
       " (6.450310559006211, 'society journals'),\n",
       " (6.450310559006211, 'six journals'),\n",
       " (6.44663382594417, 'oa ),'),\n",
       " (6.4423076923076925, 'j ., cockayne'),\n",
       " (6.4423076923076925, 'j ., adamson'),\n",
       " (6.416666666666666, 'new business models'),\n",
       " (6.3589743589743595, 'p ., loh'),\n",
       " (6.3493589743589745, 'article within'),\n",
       " (6.339285714285714, 'possible using analysis'),\n",
       " (6.305555555555555, 'two years'),\n",
       " (6.305555555555555, 'two years'),\n",
       " (6.305555555555555, 'process submissions'),\n",
       " (6.274725274725275, 'per year'),\n",
       " (6.274725274725275, 'per year'),\n",
       " (6.2727272727272725, 'one'),\n",
       " (6.2727272727272725, 'one'),\n",
       " (6.2727272727272725, 'one'),\n",
       " (6.270325203252033, 'publication date resulted'),\n",
       " (6.266176470588236, 'longitudinal study would'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.265508684863524, 'size group'),\n",
       " (6.252688172043011, 'size groups'),\n",
       " (6.252688172043011, 'size groups'),\n",
       " (6.25, 'paper copies'),\n",
       " (6.25, 'mathematical model'),\n",
       " (6.219354838709677, 'size strata'),\n",
       " (6.208333333333334, 'data collection'),\n",
       " (6.194444444444445, 'among articles'),\n",
       " (6.166666666666667, 'creates backlogs'),\n",
       " (6.15, 'around twice'),\n",
       " (6.141176470588236, 'ﬁrst broad study'),\n",
       " (6.13076923076923, '4 7'),\n",
       " (6.129032258064516, 'journal size'),\n",
       " (6.129032258064516, 'journal size'),\n",
       " (6.129032258064516, 'journal size'),\n",
       " (6.103658536585366, 'publication period'),\n",
       " (6.103658536585366, 'publication period'),\n",
       " (6.1, 'impact factor'),\n",
       " (6.1, 'impact factor'),\n",
       " (6.041666666666666, 'yearly article'),\n",
       " (6.022177419354838, 'scholarly journal'),\n",
       " (6.020325203252032, 'publication ahead'),\n",
       " (6.0, 'working paper'),\n",
       " (6.0, 'usually asked'),\n",
       " (6.0, 'paper form'),\n",
       " (6.0, 'page limits'),\n",
       " (6.0, 'include arts'),\n",
       " (6.0, 'four percent'),\n",
       " (6.0, 'fairly small'),\n",
       " (6.0, 'country rank'),\n",
       " (6.0, '2004'),\n",
       " (6.0, '2004'),\n",
       " (5.994047619047619, '1980 ),'),\n",
       " (5.958333333333334, 'data source'),\n",
       " (5.950310559006211, 'statistical journals'),\n",
       " (5.950310559006211, 'sized journals'),\n",
       " (5.950310559006211, 'psychology journals'),\n",
       " (5.950310559006211, 'journals wereordered'),\n",
       " (5.950310559006211, 'journals require'),\n",
       " (5.950310559006211, 'journals containing'),\n",
       " (5.950310559006211, 'journals containing'),\n",
       " (5.950310559006211, 'highlycited journals'),\n",
       " (5.950310559006211, 'five journals'),\n",
       " (5.950310559006211, 'articleswithin journals'),\n",
       " (5.950310559006211, '500scholarly journals'),\n",
       " (5.942890442890443, '7 months'),\n",
       " (5.942890442890443, '7 months'),\n",
       " (5.918803418803419, 'articles within'),\n",
       " (5.875, 'reviewed journalsbo'),\n",
       " (5.875, 'reviewed articleduring'),\n",
       " (5.853658536585366, 'publication lag'),\n",
       " (5.800000000000001, 'information research'),\n",
       " (5.8, 'engineering'),\n",
       " (5.779411764705882, 'electronic copies'),\n",
       " (5.75, 'management'),\n",
       " (5.75, 'management'),\n",
       " (5.75, 'citation rates'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.730769230769231, 'informetrics 7'),\n",
       " (5.708333333333334, 'scopus provides'),\n",
       " (5.70310391363023, 'open review'),\n",
       " (5.70310391363023, 'open review'),\n",
       " (5.7, 'three points'),\n",
       " (5.7, '3'),\n",
       " (5.7, '3'),\n",
       " (5.7, '3'),\n",
       " (5.7, '3'),\n",
       " (5.681818181818182, 'also considerably'),\n",
       " (5.666666666666666, 'signiﬁcant delays'),\n",
       " (5.666666666666666, 'periodical ’'),\n",
       " (5.666666666666666, 'page limitsresulting'),\n",
       " (5.619047619047619, 'ﬁxed factors'),\n",
       " (5.611111111111111, 'publish articles'),\n",
       " (5.611111111111111, 'individual articles'),\n",
       " (5.611111111111111, 'individual articles'),\n",
       " (5.611111111111111, 'articles submitted'),\n",
       " (5.6, 'typically bundles'),\n",
       " (5.6, 'largely impact'),\n",
       " (5.564102564102564, 'earlier studies'),\n",
       " (5.564102564102564, 'earlier studies'),\n",
       " (5.564102564102564, 'earlier studies'),\n",
       " (5.555555555555555, 'two things'),\n",
       " (5.555555555555555, 'two libraries'),\n",
       " (5.543010752688172, 'total time'),\n",
       " (5.53726362625139, 'oa journal'),\n",
       " (5.529411764705882, 'electronic holdings'),\n",
       " (5.523809523809524, 'average delays'),\n",
       " (5.5, 'web site'),\n",
       " (5.5, 'web site'),\n",
       " (5.5, 'steady state'),\n",
       " (5.5, 'statisticsare normalized'),\n",
       " (5.5, 'see'),\n",
       " (5.5, 'randomly ordered'),\n",
       " (5.5, 'publish versions'),\n",
       " (5.5, 'hierarchical classiﬁcation'),\n",
       " (5.5, 'econometrics'),\n",
       " (5.5, 'biomedicine'),\n",
       " (5.5, 'biomedicine'),\n",
       " (5.483704974271012, '2002 ).'),\n",
       " (5.483704974271012, '2002 ).'),\n",
       " (5.483704974271012, '2002 ).'),\n",
       " (5.483704974271012, '2002 ).'),\n",
       " (5.483704974271012, '2002 ).'),\n",
       " (5.480769230769231, 'previous studies'),\n",
       " (5.480769230769231, 'previous studies'),\n",
       " (5.461666666666666, 'published times'),\n",
       " (5.458333333333334, 'detailed data'),\n",
       " (5.458333333333334, 'data included'),\n",
       " (5.454545454545455, 'may ﬁnd'),\n",
       " (5.450310559006211, 'npg journals'),\n",
       " (5.448717948717949, 'peer review'),\n",
       " (5.448717948717949, 'peer review'),\n",
       " (5.444444444444445, 'articles might'),\n",
       " (5.421052631578947, 'open letter'),\n",
       " (5.421052631578947, 'open accessibility'),\n",
       " (5.419354838709678, 'size insuch'),\n",
       " (5.419354838709678, 'size could'),\n",
       " (5.4, 'main reason'),\n",
       " (5.4, 'main caveat'),\n",
       " (5.4, 'around 1'),\n",
       " (5.376344086021505, 'journal ’'),\n",
       " (5.376344086021505, 'journal ’'),\n",
       " (5.373983739837398, 'publishing delays'),\n",
       " (5.355769230769231, 'studies would'),\n",
       " (5.353658536585366, 'paper publication'),\n",
       " (5.333333333333334, 'working papers'),\n",
       " (5.333333333333334, 'publicationspeed resulting'),\n",
       " (5.333333333333334, 'papers submitted'),\n",
       " (5.333333333333334, 'biomedical sciences'),\n",
       " (5.333333333333334, 'alternative models'),\n",
       " (5.318428184281843, 'publishing articles'),\n",
       " (5.318428184281843, 'publishing articles'),\n",
       " (5.318428184281843, 'publishing articles'),\n",
       " (5.3076923076923075, 'amongjournals within'),\n",
       " (5.285714285714286, 'factors result'),\n",
       " (5.2745098039215685, 'pilot study'),\n",
       " (5.273658536585366, 'publication times'),\n",
       " (5.273658536585366, 'publication times'),\n",
       " (5.273658536585366, 'publication times'),\n",
       " (5.273658536585366, 'publication times'),\n",
       " (5.273658536585366, 'publication times'),\n",
       " (5.262872628726287, 'publishing process'),\n",
       " (5.255131964809384, 'economics journal'),\n",
       " (5.25, 'citation counts'),\n",
       " (5.241666666666667, 'article information'),\n",
       " (5.23908918406072, 'electronic journal'),\n",
       " (5.236728837876614, 'electronic publishing'),\n",
       " (5.236728837876614, 'electronic publishing'),\n",
       " (5.230769230769231, 'future studies'),\n",
       " (5.223030303030303, 'delay times'),\n",
       " (5.223030303030303, 'delay times'),\n",
       " (5.2142857142857135, '20 0'),\n",
       " (5.209677419354838, 'international journal'),\n",
       " (5.202051282051282, 'review times'),\n",
       " (5.202051282051282, 'review times'),\n",
       " (5.2, 'contains information'),\n",
       " (5.199999999999999, 'mean std'),\n",
       " (5.1923076923076925, '., dumville'),\n",
       " (5.169230769230769, 'variance components'),\n",
       " (5.169230769230769, 'variance components'),\n",
       " (5.166666666666666, 'response delays'),\n",
       " (5.152777777777778, 'published articles'),\n",
       " (5.152777777777778, 'articles published'),\n",
       " (5.146627565982405, 'size based'),\n",
       " (5.1, 'signiﬁcantly different'),\n",
       " (5.1, 'different sub'),\n",
       " (5.084677419354838, 'particular journal'),\n",
       " (5.083333333333334, 'citation rate'),\n",
       " (5.055555555555555, 'overall process'),\n",
       " (5.043010752688172, 'scimago journal'),\n",
       " (5.029411764705882, 'electronic versions'),\n",
       " (5.023809523809524, 'ﬁnal version'),\n",
       " (5.020325203252032, 'submissionto publication'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.020325203252032, 'publication delays'),\n",
       " (5.010347376201035, 'publishing delay'),\n",
       " (5.0, 'ﬁnally publishes'),\n",
       " (5.0, 'wider dissemination'),\n",
       " (5.0, 'varied between6'),\n",
       " (5.0, 'strong incentive'),\n",
       " (5.0, 'standard part'),\n",
       " (5.0, 'standard errors'),\n",
       " (5.0, 'standard errors'),\n",
       " (5.0, 'speciﬁc disciplines'),\n",
       " (5.0, 'signiﬁcant burden'),\n",
       " (5.0, 'rent form'),\n",
       " (5.0, 'recent survey'),\n",
       " (5.0, 'publish thisinformation'),\n",
       " (5.0, 'physics'),\n",
       " (5.0, 'physics'),\n",
       " (5.0, 'part reﬂects'),\n",
       " (5.0, 'many disciplines'),\n",
       " (5.0, 'longer periods'),\n",
       " (5.0, 'limited dissemination'),\n",
       " (5.0, 'last articlepublished'),\n",
       " (5.0, 'labor intensive'),\n",
       " (5.0, 'individual reviews'),\n",
       " (5.0, 'indiana university'),\n",
       " (5.0, 'important reason'),\n",
       " (5.0, 'important aspect'),\n",
       " (5.0, 'graphic form'),\n",
       " (5.0, 'fairly inaccurate'),\n",
       " (5.0, 'explicitly studied'),\n",
       " (5.0, 'dissemination medium'),\n",
       " (5.0, 'corresponding topics'),\n",
       " (5.0, 'consuming work'),\n",
       " (5.0, 'considerably shorter'),\n",
       " (5.0, 'considerably shortened'),\n",
       " (5.0, 'averages similar'),\n",
       " (5.0, 'attractive alternative'),\n",
       " (5.0, '6'),\n",
       " (5.0, '6'),\n",
       " (5.0, '2700 paperspublished'),\n",
       " (4.975, 'different ﬁelds'),\n",
       " (4.970588235294118, 'check access'),\n",
       " (4.95, 'publisher included'),\n",
       " (4.944444444444445, 'articles accounted'),\n",
       " (4.933333333333334, 'different sciences'),\n",
       " (4.92, 'times fromsubmission'),\n",
       " (4.909677419354839, 'journal rather'),\n",
       " (4.909677419354839, 'journal level'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.909214092140921, 'publication process'),\n",
       " (4.892857142857142, 'even twice'),\n",
       " (4.876344086021505, 'scientiﬁc journal'),\n",
       " (4.866666666666667, 'three decades'),\n",
       " (4.866666666666667, 'publisher ’'),\n",
       " (4.861111111111111, 'publishers included'),\n",
       " (4.858585858585858, 'delay process'),\n",
       " (4.857142857142858, 'online version'),\n",
       " (4.857142857142858, 'average rangeyohe'),\n",
       " (4.853658536585366, 'publication lags'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.837606837606837, 'review process'),\n",
       " (4.834677419354838, 'journal quality'),\n",
       " (4.833333333333334, 'nine groups'),\n",
       " (4.833333333333334, 'decline might'),\n",
       " (4.818181818181818, 'science'),\n",
       " (4.818181818181818, 'science'),\n",
       " (4.818181818181818, 'science'),\n",
       " (4.769230769230769, 'variance component'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.763425253991292, '2012 ).'),\n",
       " (4.75, 'web mediumlends'),\n",
       " (4.75, 'new york'),\n",
       " (4.75, 'new types'),\n",
       " (4.75, 'citation measure'),\n",
       " (4.736111111111111, 'articles would'),\n",
       " (4.727272727272727, 'discipline category'),\n",
       " (4.716666666666667, 'accepted manuscripts'),\n",
       " (4.709677419354838, 'neuroscience journal'),\n",
       " (4.709677419354838, 'journal website'),\n",
       " (4.709677419354838, 'journal wasin'),\n",
       " (4.709677419354838, 'another journal'),\n",
       " (4.7073170731707314, 'stop publishing'),\n",
       " (4.7073170731707314, 'print publishing'),\n",
       " (4.704545454545455, 'editors may'),\n",
       " (4.6923076923076925, 'n .,'),\n",
       " (4.6923076923076925, '., targino'),\n",
       " (4.6911764705882355, 'detailed study'),\n",
       " (4.681818181818182, 'also restricted'),\n",
       " (4.67688679245283, '1980 ).'),\n",
       " (4.666666666666667, 'clear development'),\n",
       " (4.666666666666667, '1999'),\n",
       " (4.666666666666667, '1999'),\n",
       " (4.666666666666666, 'particularjournal ’'),\n",
       " (4.666666666666666, 'muchlonger delays'),\n",
       " (4.666666666666666, 'law reviews'),\n",
       " (4.666666666666666, 'everyone ’'),\n",
       " (4.666666666666666, 'delays differ'),\n",
       " (4.666666666666666, 'ams members'),\n",
       " (4.6566888396156685, 'publication delay'),\n",
       " (4.6566888396156685, 'publication delay'),\n",
       " (4.619528619528619, '5 months'),\n",
       " (4.619528619528619, '5 months'),\n",
       " (4.619528619528619, '5 months'),\n",
       " (4.619528619528619, '5 months'),\n",
       " (4.619528619528619, '5 months'),\n",
       " (4.612121212121211, '4 months'),\n",
       " (4.612121212121211, '4 months'),\n",
       " (4.611111111111111, 'invited articles'),\n",
       " (4.611111111111111, 'bundle articles'),\n",
       " (4.611111111111111, 'articles sampled'),\n",
       " (4.603658536585366, 'publication date'),\n",
       " (4.6, 'several journalsat'),\n",
       " (4.6, 'several iterations'),\n",
       " (4.6, 'different forms'),\n",
       " (4.6, 'different disciplines'),\n",
       " (4.6, '31 12'),\n",
       " (4.6, '08 12'),\n",
       " (4.583877995642702, '8 5'),\n",
       " (4.583333333333334, 'manuscriptis accepted'),\n",
       " (4.575, 'particular publisher'),\n",
       " (4.571428571428571, 'signiﬁcant differences'),\n",
       " (4.566820276497696, 'average time'),\n",
       " (4.555555555555555, 'often publishedindividually'),\n",
       " (4.555555555555555, 'often publishedearlier'),\n",
       " (4.555555555555555, 'often justiﬁed'),\n",
       " (4.555555555555555, 'often highlighted'),\n",
       " (4.55188679245283, '2 ).'),\n",
       " (4.55188679245283, '2 ).'),\n",
       " (4.545454545454545, 'economics andmanagement'),\n",
       " (4.541666666666666, 'ﬁnally published'),\n",
       " (4.541666666666666, 'published monthly'),\n",
       " (4.541666666666666, 'published elsewhere'),\n",
       " (4.541666666666666, 'openly published'),\n",
       " (4.541666666666666, 'issuewas published'),\n",
       " (4.541666666666666, 'acceptedto published'),\n",
       " (4.532407407407407, '5 17'),\n",
       " (4.529411764705882, 'electronic format'),\n",
       " (4.520325203252032, 'ﬁnal publication'),\n",
       " (4.520325203252032, 'ﬁnal publication'),\n",
       " (4.520325203252032, 'ﬁnal publication'),\n",
       " (4.5, 'timebefore email'),\n",
       " (4.5, 'theamerican society'),\n",
       " (4.5, 'supplementary dataj'),\n",
       " (4.5, 'random effects'),\n",
       " (4.5, 'public policy'),\n",
       " (4.5, 'marginally faster'),\n",
       " (4.5, 'largest amount'),\n",
       " (4.5, 'increased substantiallyin'),\n",
       " (4.5, 'comparing candidates'),\n",
       " (4.5, 'centric view'),\n",
       " (4.492307692307692, 'g .,'),\n",
       " (4.462121212121212, '2 months'),\n",
       " (4.4423076923076925, 'j .,'),\n",
       " (4.4423076923076925, 'j .,'),\n",
       " (4.434589800443459, 'based publishing'),\n",
       " (4.412698412698413, 'often used'),\n",
       " (4.4, 'publishedyesnomean std'),\n",
       " (4.4, 'deviation std'),\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Rake()\n",
    "r.extract_keywords_from_sentences(pdf_six_sent_tokens)\n",
    "r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "r_kw = r.extract_keywords_from_text(pdf)\n",
    "r.get_ranked_phrases()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 journals 7 journals 6 journals 3 social science journals 3 natural science journals one journal15 journals10 journals one journal 7 journals 14 journals 28 commercial',\n",
       " '19971992 1985 – 1999 1997 2002 2004 2004 2005 2009 economics econometrics statistics econ ., management physics',\n",
       " 'ac ceptedche mistry engin eering biomedicine physics earth science mathema',\n",
       " '1577 /$ – see front matter © http :// dx',\n",
       " 'analytical chemistry geoscience mainly engineering agriculture biomedicine civil engineering cross',\n",
       " 'two conventional 26 iranian journals 1980 1986 – 1990 1994',\n",
       " 'revised form 3 september 2013accepted 4 september 2013keywords',\n",
       " 'acceptdiscipline journal size journal article × size discipline total 3',\n",
       " 'publishdiscipline journal size journal article × size discipline total 5',\n",
       " 'publishingin open access journals (“ gold oa ”)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.extract_keywords_from_text(\"The publishing delay in scholarly peer-reviewed journals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.0, 'scholarly peer'),\n",
       " (4.0, 'reviewed journals'),\n",
       " (4.0, 'publishing delay')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "seek of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-34a6e7ba9f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpdf_pdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36mgetPage\u001b[1;34m(self, pageNumber)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[1;31m#assert not self.trailer.has_key(\"/Encrypt\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflattenedPages\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflattenedPages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpageNumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36m_flatten\u001b[1;34m(self, pages, inherit, indirectRef)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpages\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflattenedPages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1505\u001b[1;33m             \u001b[0mcatalog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrailer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"/Root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1506\u001b[0m             \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatalog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"/Pages\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\generic.py\u001b[0m in \u001b[0;36mgetObject\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36mgetObject\u001b[1;34m(self, indirectReference)\u001b[0m\n\u001b[0;32m   1596\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxref\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindirectReference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindirectReference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Uncompressed Object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindirectReference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindirectReference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1599\u001b[0m             \u001b[0midnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadObjectHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midnum\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mindirectReference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midnum\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxrefIndex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: seek of closed file"
     ]
    }
   ],
   "source": [
    "pdf_pdf.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8360"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"References\" in pdf_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Creating a manual Regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_date_capture(pdf_text):\n",
    "\n",
    "    # REGEX PATTERNS - RECEIVED & SUBMITTED\n",
    "    # 1 - 10 MAY 1960:\n",
    "    rec_1 =  \"(?:(?:received|submitted)\\s?(?:on|date)?\\s?\\:?\\s?)(\\d{1,2}\\s*(Jan(uary|.)?|Feb(ruary|.)?|Mar(ch|.)?|Apr(il|.)?|May|Jun(e|.)?|Jul(y|.)?|Aug(ust|.)?|Sep(tember|.)?|Oct(ober)?|Nov(ember|.)?|Dec(ember|.)?)\\s*(19|20)\\d{2})\"\n",
    "    # 2 - MAY 10, 1960\n",
    "    rec_2 = \"(?:(?:received|submitted)\\s?(?:on|date)?\\s?\\:?\\s?)((Jan(uary|.)?|Feb(ruary|.)?|Mar(ch|.)?|Apr(il|.)?|May|Jun(e|.)?|Jul(y|.)?|Aug(ust|.)?|Sep(tember|.)?|Oct(ober|.)?|Nov(ember|.)?|Dec(ember|.)?)\\s?\\d{1,2}\\,?\\s?(19|20)\\d{2})\"\n",
    "    # 3 - MAY 1960\n",
    "    rec_3 = \"(?:(?:received|submitted)\\s?(?:on|date)?\\s?\\:?\\s?)((Jan(uary|.)?|Feb(ruary|.)?|Mar(ch|.)?|Apr(il|.)?|May|Jun(e|.)?|Jul(y|.)?|Aug(ust|.)?|Sep(tember|.)?|Oct(ober|.)?|Nov(ember|.)?|Dec(ember|.)?)\\s*(19|20)\\d{2})\"\n",
    "    # 4 - 10/05/1960 OR 10.05.1960 OR 10/05/1960\n",
    "    rec_4 = \"(?:(?:received|submitted)\\s?(?:on|date)?\\s?\\:?\\s?)([1-3][0-9](\\.|\\-|\\/|\\:)?[0-1][0-9](\\.|\\-|\\/\\:)?(19|20)\\d{2})\"\n",
    "\n",
    "    rec_patterns = [rec_1, rec_2, rec_3, rec_4]\n",
    "\n",
    "    for pattern in rec_patterns:\n",
    "        comp_pattern = re.compile(pattern, re.IGNORECASE) \n",
    "        try:\n",
    "            date = re.search(comp_pattern,pdf_text).group(1)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://www.nature.com/articles/eye201520.pdf\n"
     ]
    }
   ],
   "source": [
    "# Get a random pdf_read:\n",
    "\n",
    "#random_dir_url = date_df_ok[date_df_ok.Rec_date.notna()].direct_url.sample(1).values[0]\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36'}\n",
    "\n",
    "pdf_req = requests.get(random_dir_url,headers=HEADERS)\n",
    "\n",
    "print(pdf_req)\n",
    "pdf_io = io.BytesIO(pdf_req.content)\n",
    "pdf_read = extract_text(pdf_io,page_numbers=[])\n",
    "\n",
    "print(random_dir_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dir_url = \"https://www.nature.com/articles/eye201520.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_read = pdf_read.replace(\"\\n\",\" \")\n",
    "pdf_read = re.sub(' +', ' ', pdf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_reg_modified.search(pdf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(email_reg_modified,pdf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: nan\n",
      "Country: United States\n",
      "University: nan\n"
     ]
    }
   ],
   "source": [
    "print(f\"Email: {email_converter(pdf_read)}\")\n",
    "\n",
    "print(f\"Country: {country_converter(pdf_read)}\")\n",
    "\n",
    "print(f\"University: {univ_converter(pdf_read)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 2009\n"
     ]
    }
   ],
   "source": [
    "print(rec_date_capture(pdf_read))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Preprocessing for Keyword Extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the analysis, it is seen that the best (most efficient) method for Content Analysis will be a manual preprocc. & rake_nltk.\n",
    "\n",
    "Fortunately, as the \"text\"s in question are scientific articles, not a lot of preproc. is necessary, but still required. These are determined as:\n",
    "\n",
    "- Remove:\n",
    "    - e-mail, website links, date, number, paranthesis, brackets, \"Figure ...\"\n",
    "    - stopwords\n",
    "    - any word w/ len: <2 & >20\n",
    "- Slice after \"References\" or \"Acknowledgements\" (but from end to begin.)\n",
    "- lowercase all & word_tokenizer\n",
    "- Lemmatize\n",
    "\n",
    "---\n",
    "\n",
    "Observations:\n",
    "\n",
    "* rake-nltk seems to perform quite poorly!\n",
    "* KeyBERT seems like a good potential tool for the project!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import snowballstemmer\n",
    "\n",
    "from keybert import KeyBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP - Prepocessing:\n",
    "\n",
    "#pdf_read = pdf_read.replace(\"\\n\",\" \")\n",
    "#pdf_read = re.sub(' +', ' ', pdf_read)\n",
    "\n",
    "# Run get_dates()\n",
    "# Run get_affil()\n",
    "\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#stemmer = snowballstemmer.stemmer('english')\n",
    "#kw_model = KeyBERT()\n",
    "\n",
    "#stopwords_set = set(stopwords.words(\"english\"))\n",
    "#words_set = set(words.words())\n",
    "\n",
    "# Lowercase all:\n",
    "pdf_modified = pdf_read.lower()\n",
    "\n",
    "# Removing \"References\":\n",
    "pdf_modified = \"\".join(pdf_modified.split(\"references\")[:-1])\n",
    "\n",
    "# Remove URL:\n",
    "pdf_modified = re.sub(r'http\\S+', '', pdf_modified)\n",
    "\n",
    "# Remove emails:\n",
    "pdf_modified = re.sub(r\"\\S*@\\S*\\s?\", \"\", pdf_modified)\n",
    "\n",
    "# Remove everything in brackets & paranthesis:\n",
    "pdf_modified = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", pdf_modified)\n",
    "\n",
    "# Remove punctuation:\n",
    "pdf_modified = re.sub(r'[^\\w\\s]', '', pdf_modified)\n",
    "\n",
    "# Remove numbers\n",
    "pdf_modified = re.sub(r'[0-9]', '', pdf_modified)\n",
    "\n",
    "# Remove HTML tags:\n",
    "pdf_modified = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', pdf_modified)\n",
    "\n",
    "# Remove single letters:\n",
    "pdf_modified = re.sub(r\"(?<=(^|\\s))\\D(\\s|$)\",\"\", pdf_modified)\n",
    "\n",
    "# Remove multiple spaces:\n",
    "pdf_modified = re.sub(' +', ' ', pdf_modified)\n",
    "\n",
    "# Tokenize:\n",
    "#pdf_modified = word_tokenize(pdf_modified)\n",
    "\n",
    "# Simple Lemmatization Trial:\n",
    "#pdf_modified = \" \".join([wordnet_lemmatizer.lemmatize(word) for word in pdf_modified])\n",
    "\n",
    "# Removing Stopwords & <2 - >15 words & Lemmatizing:\n",
    "#pdf_modified = [wordnet_lemmatizer.lemmatize(word) for word in pdf_modified if word not in stopwords_set if word in words_set if len(word)>2 if len(word)<15]\n",
    "\n",
    "# Re-merging the text:\n",
    "#pdf_modified = \" \".join(pdf_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('volatility', 0.3955), ('varianceoptimal', 0.3739), ('volatil', 0.367), ('leverage', 0.3311), ('semimartingale', 0.3199), ('variance', 0.3083), ('levy', 0.3049), ('variation', 0.2992), ('stochastic', 0.2828), ('stock', 0.2822)]\n",
      "Lemma: {'stock', 'leverage', 'variation', 'varianceoptimal', 'semimartingale', 'levy', 'stochastic', 'variance', 'volatil', 'volatility'} - len: 10\n",
      "Stem: {'stock', 'levi', 'leverag', 'semimartingal', 'variat', 'varianc', 'varianceoptim', 'volatil', 'stochast'} - len: 9\n",
      "LemmaStem: {'stock', 'levi', 'leverag', 'semimartingal', 'variat', 'varianc', 'varianceoptim', 'volatil', 'stochast'} - len: 9\n"
     ]
    }
   ],
   "source": [
    "keywords = kw_model.extract_keywords(pdf_modified ,keyphrase_ngram_range=(1, 1), stop_words=\"english\", top_n=10)\n",
    "print(keywords)\n",
    "\n",
    "kw_lemma = [wordnet_lemmatizer.lemmatize(word) for word, sc in keywords]\n",
    "kw_stem = [stemmer.stemWord(word) for word, sc in keywords]\n",
    "kw_lemmastem = [stemmer.stemWord(word) for word in kw_lemma]\n",
    "\n",
    "print(f\"Lemma: {set(kw_lemma)} - len: {len(set(kw_lemma))}\")\n",
    "print(f\"Stem: {set(kw_stem)} - len: {len(set(kw_stem))}\")\n",
    "print(f\"LemmaStem: {set(kw_lemmastem)} - len: {len(set(kw_lemmastem))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize:\n",
    "pdf_modified = word_tokenize(pdf_modified)\n",
    "\n",
    "# Simple Lemmatization Trial:\n",
    "pdf_modified = \" \".join([wordnet_lemmatizer.lemmatize(word) for word in pdf_modified])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('recombination', 0.4157), ('recombinationa', 0.3894), ('recombinationb', 0.3833), ('schizosaccharomyces', 0.3808), ('recombinant', 0.3778), ('recombinasemediated', 0.37), ('gene', 0.3673), ('mutation', 0.3494), ('genotype', 0.3489), ('recombina', 0.3476)]\n",
      "Lemma: {'recombinasemediated', 'schizosaccharomyces', 'gene', 'mutation', 'recombination', 'recombinationa', 'genotype', 'recombinationb', 'recombinant', 'recombina'} - len: 10\n",
      "Stem: {'schizosaccharomyc', 'recombin', 'mutat', 'gene', 'genotyp', 'recombinasemedi', 'recombinationa', 'recombinationb', 'recombina'} - len: 9\n",
      "LemmaStem: {'schizosaccharomyc', 'recombin', 'mutat', 'gene', 'genotyp', 'recombinasemedi', 'recombinationa', 'recombinationb', 'recombina'} - len: 9\n"
     ]
    }
   ],
   "source": [
    "keywords = kw_model.extract_keywords(pdf_modified ,keyphrase_ngram_range=(1, 1), stop_words=\"english\", top_n=10)\n",
    "print(keywords)\n",
    "\n",
    "kw_lemma = [wordnet_lemmatizer.lemmatize(word) for word, sc in keywords]\n",
    "kw_stem = [stemmer.stemWord(word) for word, sc in keywords]\n",
    "kw_lemmastem = [stemmer.stemWord(word) for word in kw_lemma]\n",
    "\n",
    "print(f\"Lemma: {set(kw_lemma)} - len: {len(set(kw_lemma))}\")\n",
    "print(f\"Stem: {set(kw_stem)} - len: {len(set(kw_stem))}\")\n",
    "print(f\"LemmaStem: {set(kw_lemmastem)} - len: {len(set(kw_lemmastem))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('research tourism', 0.6241), ('tourism research', 0.6149), ('tourism researchers', 0.5943), ('tourism study', 0.5822), ('communities tourism', 0.5771)]\n"
     ]
    }
   ],
   "source": [
    "keywords2 = kw_model.extract_keywords(pdf_modified ,keyphrase_ngram_range=(1, 2), stop_words=\"english\")\n",
    "print(keywords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('income', -0.0462), ('poor', 0.1332), ('governance', -0.0135), ('constituency', 0.1646), ('oligarchic', 0.0591)]\n"
     ]
    }
   ],
   "source": [
    "keywords3 = kw_model.extract_keywords(pdf_modified ,keyphrase_ngram_range=(1, 1), use_maxsum=True)\n",
    "print(keywords3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('income wealthy', -0.0106), ('poor democracy', 0.0501), ('redistribution poor', 0.0787), ('oligarchy ing', 0.0689), ('research oligarchy', 0.0611)]\n"
     ]
    }
   ],
   "source": [
    "keywords4 = kw_model.extract_keywords(pdf_modified ,keyphrase_ngram_range=(1, 2), use_maxsum=True)\n",
    "print(keywords4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('democracy oligarchy', 0.6004), ('eu oligarchy', 0.5918), ('oligarchy representativeness', 0.5473), ('oligarchy unequal', 0.5394), ('oligarchy politics', 0.5258)]\n"
     ]
    }
   ],
   "source": [
    "keywords5 = kw_model.extract_keywords(pdf_read, keyphrase_ngram_range=(1, 2))\n",
    "print(keywords5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('democratic representation', 0.06), ('governance issn', 0.0372), ('government european', 0.1113), ('article democracy', 0.1076), ('oligarchy poverty', 0.1695)]\n"
     ]
    }
   ],
   "source": [
    "keywords6 = kw_model.extract_keywords(pdf_read, keyphrase_ngram_range=(1, 2), use_maxsum=True)\n",
    "print(keywords6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeyBERT has the best potential for being the keyword extractor. However, it takes a REALLY (9-10 secs) for it to run on the whole pdf_read.\n",
    "\n",
    "The alternative version, pdf_modified, is faster for Keybert, but the preprocessing itself takes around 9-19 seconds, so the overall process is actualy even longer!\n",
    "\n",
    "As a potential \"middle ground\" between the two, preprocessing can be scraped almost completely, except for the \"References slicing\". This will be tested below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing \"References\":\n",
    "pdf_simple_mod = \"\".join(pdf_read.lower().split(\"references\")[:-1])\n",
    "pdf_simple_mod = re.sub(' +', ' ', pdf_simple_mod)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92ba50c92c9dc11b366869717e90d544d23b7140e20708921d0ff91f276d2e3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
